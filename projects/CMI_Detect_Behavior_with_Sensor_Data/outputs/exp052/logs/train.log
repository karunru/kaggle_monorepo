08/24/2025 01:22:34 AM INFO __main__: Starting cross-validation training
08/24/2025 01:22:34 AM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp052', 'name': 'exp052_convnext_se_integration', 'description': '4-layer ConvNeXt1D blocks with SE attention', 'tags': ['imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '1-layer-convnext']}, 'paths': {'output_dir': '../../../outputs/exp052'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 20, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1, 'lstm_hidden_dim': 128, 'lstm_num_layers': 1, 'lstm_bidirectional': True, 'dense1_dim': 256, 'dense2_dim': 128, 'dense1_dropout': 0.5, 'dense2_dropout': 0.3, 'cnn_block1_out_channels': 64, 'cnn_block2_out_channels': 128, 'cnn_block1_kernel_size': 3, 'cnn_block2_kernel_size': 5, 'cnn_dropout': 0.3, 'gru_dropout': 0.4, 'cnn_block3_out_channels': 256, 'cnn_block3_kernel_size': 7, 'cnn_block4_out_channels': 512, 'cnn_block4_kernel_size': 9}, 'training': {'seed': 42, 'batch_size': 256, 'num_workers': 8, 'epochs': 200, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2, 'kl_weight': 0.1, 'kl_temperature': 1.0, 'auto_weighting': 'none', 'auto_weight_clamp': (-10.0, 10.0), 'uncertainty_init_value': 0.0, 'use_mixup': True}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': False, 'beta': 0.9999, 'update_every': 1, 'update_after_step': 100}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'enable_randaugment': True, 'randaugment_n': 2, 'randaugment_m': 6.0, 'randaugment_prob': 0.8, 'add_noise_scale': 0.02, 'mag_scale_range': [0.9, 1.1], 'time_warp_max': 0.2, 'crop_ratio': 0.9, 'mask_ratio': 0.1, 'imu_rotation_angle_range': 0.2, 'handedness_flip_prob': 0.0, 'enable_handedness_flip': False, 'gaussian_noise_prob': 0.0, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.0, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.0, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp052', 'wandb_tags': ['exp052', 'imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '4-layer-convnext']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 30, 'min_delta': 0.0001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp052', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/24/2025 01:22:34 AM INFO __main__: Starting training for fold 0
08/24/2025 01:24:37 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 01:26:20 AM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/train.py", line 246, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/train.py", line 169, in train_single_fold
    trainer.fit(model, data_module)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
    ~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
    ~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/model.py", line 1075, in validation_step
    multiclass_logits, binary_logits, nine_class_logits = self(imu, attention_mask, demographics)
                                                          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/model.py", line 910, in forward
    return self.model(imu, demographics_embedding)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/model.py", line 582, in forward
    gru_out, _ = self.bigru(merged)
                 ~~~~~~~~~~^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py", line 1391, in forward
    self.check_forward_args(input, hx, batch_sizes)
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py", line 363, in check_forward_args
    self.check_input(input, batch_sizes)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py", line 314, in check_input
    raise RuntimeError(
        f"input.size(-1) must be equal to input_size. Expected {self.input_size}, got {input.size(-1)}"
    )
RuntimeError: input.size(-1) must be equal to input_size. Expected 512, got 64
08/24/2025 01:31:36 AM INFO __main__: Starting cross-validation training
08/24/2025 01:31:36 AM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp052', 'name': 'exp052_convnext_se_integration', 'description': '4-layer ConvNeXt1D blocks with SE attention', 'tags': ['imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '1-layer-convnext']}, 'paths': {'output_dir': '../../../outputs/exp052'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 20, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1, 'lstm_hidden_dim': 128, 'lstm_num_layers': 1, 'lstm_bidirectional': True, 'dense1_dim': 256, 'dense2_dim': 128, 'dense1_dropout': 0.5, 'dense2_dropout': 0.3, 'cnn_block1_out_channels': 128, 'cnn_block1_kernel_size': 3, 'cnn_dropout': 0.3, 'gru_dropout': 0.4}, 'training': {'seed': 42, 'batch_size': 256, 'num_workers': 8, 'epochs': 200, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2, 'kl_weight': 0.1, 'kl_temperature': 1.0, 'auto_weighting': 'none', 'auto_weight_clamp': (-10.0, 10.0), 'uncertainty_init_value': 0.0, 'use_mixup': True}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': False, 'beta': 0.9999, 'update_every': 1, 'update_after_step': 100}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'enable_randaugment': True, 'randaugment_n': 2, 'randaugment_m': 6.0, 'randaugment_prob': 0.8, 'add_noise_scale': 0.02, 'mag_scale_range': [0.9, 1.1], 'time_warp_max': 0.2, 'crop_ratio': 0.9, 'mask_ratio': 0.1, 'imu_rotation_angle_range': 0.2, 'handedness_flip_prob': 0.0, 'enable_handedness_flip': False, 'gaussian_noise_prob': 0.0, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.0, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.0, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp052', 'wandb_tags': ['exp052', 'imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '4-layer-convnext']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 30, 'min_delta': 0.0001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp052', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/24/2025 01:31:36 AM INFO __main__: Starting training for fold 0
08/24/2025 01:33:16 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 01:33:16 AM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/train.py", line 246, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/train.py", line 136, in train_single_fold
    model = CMISqueezeformer(
        input_dim=actual_input_dim,  # Should be 19 for IMU-only physical features
    ...<20 lines>...
        # Note: Using simplified parameter set for IMUOnlyLSTM architecture with BERT integration
    )
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/model.py", line 712, in __init__
    self.model = IMUOnlyLSTM(
                 ~~~~~~~~~~~^
        imu_dim=input_dim,
        ^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        model_config=model_config,  # 修正
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp052/model.py", line 486, in __init__
    cnn_block2_out = model_config.cnn_block2_out_channels
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pydantic/main.py", line 891, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'ModelConfig' object has no attribute 'cnn_block2_out_channels'. Did you mean: 'cnn_block1_out_channels'?
08/24/2025 01:43:30 AM INFO __main__: Starting cross-validation training
08/24/2025 01:43:30 AM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp052', 'name': 'exp052_convnext_se_integration', 'description': '4-layer ConvNeXt1D blocks with SE attention', 'tags': ['imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '1-layer-convnext']}, 'paths': {'output_dir': '../../../outputs/exp052'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 20, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1, 'lstm_hidden_dim': 128, 'lstm_num_layers': 1, 'lstm_bidirectional': True, 'dense1_dim': 256, 'dense2_dim': 128, 'dense1_dropout': 0.5, 'dense2_dropout': 0.3, 'cnn_block1_out_channels': 64, 'cnn_block1_kernel_size': 3, 'cnn_dropout': 0.3, 'gru_dropout': 0.4}, 'training': {'seed': 42, 'batch_size': 256, 'num_workers': 8, 'epochs': 200, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2, 'kl_weight': 0.1, 'kl_temperature': 1.0, 'auto_weighting': 'none', 'auto_weight_clamp': (-10.0, 10.0), 'uncertainty_init_value': 0.0, 'use_mixup': True}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': False, 'beta': 0.9999, 'update_every': 1, 'update_after_step': 100}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'enable_randaugment': True, 'randaugment_n': 2, 'randaugment_m': 6.0, 'randaugment_prob': 0.8, 'add_noise_scale': 0.02, 'mag_scale_range': [0.9, 1.1], 'time_warp_max': 0.2, 'crop_ratio': 0.9, 'mask_ratio': 0.1, 'imu_rotation_angle_range': 0.2, 'handedness_flip_prob': 0.0, 'enable_handedness_flip': False, 'gaussian_noise_prob': 0.0, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.0, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.0, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp052', 'wandb_tags': ['exp052', 'imu_only', 'lstm', 'bigru', 'attention', 'residual_se_convnext', 'human_normalization', 'demographics', 'soft_f1_acls', 'bert', 'tsai', 'randaugment', 'imu_rotation', 'handedness_flip', 'convnext', '4-layer-convnext']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 30, 'min_delta': 0.0001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp052', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/24/2025 01:43:30 AM INFO __main__: Starting training for fold 0
08/24/2025 01:45:11 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 01:49:18 AM INFO __main__: Loading best model from: ../../../outputs/exp052/fold_0/version_1/checkpoints/epoch-107-val_cmi_score-0.7781.ckpt
08/24/2025 01:49:20 AM INFO __main__: Fold 0 results: {'fold': 0, 'val_loss': 0.849046528339386, 'val_cmi_score': 0.7781042456626892, 'val_multiclass_loss': 1.0830336809158325, 'val_binary_loss': 0.1172817051410675, 'best_model_path': '../../../outputs/exp052/fold_0/version_1/checkpoints/epoch-107-val_cmi_score-0.7781.ckpt'}
08/24/2025 01:49:20 AM INFO __main__: Starting training for fold 1
08/24/2025 01:51:02 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 01:56:00 AM INFO __main__: Loading best model from: ../../../outputs/exp052/fold_1/version_0/checkpoints/epoch-155-val_cmi_score-0.7523.ckpt
08/24/2025 01:56:03 AM INFO __main__: Fold 1 results: {'fold': 1, 'val_loss': 1.1427570581436157, 'val_cmi_score': 0.7523252367973328, 'val_multiclass_loss': 1.4693819284439087, 'val_binary_loss': 0.20767168700695038, 'best_model_path': '../../../outputs/exp052/fold_1/version_0/checkpoints/epoch-155-val_cmi_score-0.7523.ckpt'}
08/24/2025 01:56:03 AM INFO __main__: Starting training for fold 2
08/24/2025 01:57:46 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 02:02:32 AM INFO __main__: Loading best model from: ../../../outputs/exp052/fold_2/version_0/checkpoints/epoch-140-val_cmi_score-0.7834.ckpt
08/24/2025 02:02:35 AM INFO __main__: Fold 2 results: {'fold': 2, 'val_loss': 0.8969890475273132, 'val_cmi_score': 0.7833964228630066, 'val_multiclass_loss': 1.12784743309021, 'val_binary_loss': 0.12956149876117706, 'best_model_path': '../../../outputs/exp052/fold_2/version_0/checkpoints/epoch-140-val_cmi_score-0.7834.ckpt'}
08/24/2025 02:02:35 AM INFO __main__: Starting training for fold 3
08/24/2025 02:04:15 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 02:08:51 AM INFO __main__: Loading best model from: ../../../outputs/exp052/fold_3/version_0/checkpoints/epoch-137-val_cmi_score-0.7597.ckpt
08/24/2025 02:08:55 AM INFO __main__: Fold 3 results: {'fold': 3, 'val_loss': 1.0334378480911255, 'val_cmi_score': 0.7596946954727173, 'val_multiclass_loss': 1.306544303894043, 'val_binary_loss': 0.19090114533901215, 'best_model_path': '../../../outputs/exp052/fold_3/version_0/checkpoints/epoch-137-val_cmi_score-0.7597.ckpt'}
08/24/2025 02:08:55 AM INFO __main__: Starting training for fold 4
08/24/2025 02:10:36 AM INFO __main__: Using input_dim=20 (HN features: False)
08/24/2025 02:15:12 AM INFO __main__: Loading best model from: ../../../outputs/exp052/fold_4/version_0/checkpoints/epoch-129-val_cmi_score-0.7776.ckpt
08/24/2025 02:15:15 AM INFO __main__: Fold 4 results: {'fold': 4, 'val_loss': 0.8926183581352234, 'val_cmi_score': 0.7776002287864685, 'val_multiclass_loss': 1.155805230140686, 'val_binary_loss': 0.1307392716407776, 'best_model_path': '../../../outputs/exp052/fold_4/version_0/checkpoints/epoch-129-val_cmi_score-0.7776.ckpt'}
08/24/2025 02:15:15 AM INFO __main__: Cross-validation completed
08/24/2025 02:15:15 AM INFO __main__: Mean CV Loss: 0.9630 ± 0.1092
08/24/2025 02:15:15 AM INFO __main__: Mean CV CMI Score: 0.7702 ± 0.0120
08/24/2025 02:15:15 AM INFO __main__: Results saved to: ../../../outputs/exp052/cv_results.csv
08/24/2025 02:15:15 AM INFO __main__: CV results logged to WandB
