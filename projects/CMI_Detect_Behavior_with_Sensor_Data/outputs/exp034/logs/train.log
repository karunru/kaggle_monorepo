08/17/2025 10:10:53 PM INFO __main__: Starting cross-validation training
08/17/2025 10:10:53 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp034', 'name': 'exp034_afno_mixer', 'description': 'AFNO (Adaptive Fourier Neural Operator) mixer replacing BiGRU+Attention for efficient long-range dependency modeling', 'tags': ['imu_only', 'afno', 'fourier_neural_operator', 'fft_mixer', 'residual_se_cnn', 'human_normalization', 'demographics', 'soft_f1_acls', 'mish']}, 'paths': {'output_dir': '../../../outputs/exp034'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 20, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 8, 'epochs': 200, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2, 'kl_weight': 0.1, 'kl_temperature': 1.0, 'auto_weighting': 'none', 'auto_weight_clamp': (-10.0, 10.0), 'uncertainty_init_value': 0.0, 'use_mixup': True}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp034', 'wandb_tags': ['exp034', 'imu_only', 'afno', 'fourier_neural_operator', 'fft_mixer', 'residual_se_cnn', 'human_normalization', 'demographics', 'soft_f1_acls', 'mish']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 30, 'min_delta': 0.0001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp034', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/17/2025 10:10:54 PM INFO __main__: Starting training for fold 0
08/17/2025 10:12:55 PM INFO __main__: Using input_dim=20 (HN features: False)
08/17/2025 10:14:36 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/train.py", line 243, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/train.py", line 166, in train_single_fold
    trainer.fit(model, data_module)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
    ~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
    ~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/model.py", line 951, in validation_step
    multiclass_logits, binary_logits, nine_class_logits = self(imu, attention_mask, demographics)
                                                          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/model.py", line 790, in forward
    return self.model(imu, demographics_embedding)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/model.py", line 469, in forward
    h = self.afno1(h)  # 1層目のAFNOミキサ
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp034/model.py", line 352, in forward
    x_ft = torch.fft.rfft(x, dim=1)  # [batch, freq, hidden_dim] 複素数
RuntimeError: cuFFT only supports dimensions whose sizes are powers of two when computing in half precision, but got a signal size of[50]
08/17/2025 10:24:49 PM INFO __main__: Starting cross-validation training
08/17/2025 10:24:49 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp034', 'name': 'exp034_afno_mixer', 'description': 'AFNO (Adaptive Fourier Neural Operator) mixer replacing BiGRU+Attention for efficient long-range dependency modeling', 'tags': ['imu_only', 'afno', 'fourier_neural_operator', 'fft_mixer', 'residual_se_cnn', 'human_normalization', 'demographics', 'soft_f1_acls', 'mish']}, 'paths': {'output_dir': '../../../outputs/exp034'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 20, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 8, 'epochs': 200, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2, 'kl_weight': 0.1, 'kl_temperature': 1.0, 'auto_weighting': 'none', 'auto_weight_clamp': (-10.0, 10.0), 'uncertainty_init_value': 0.0, 'use_mixup': True}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp034', 'wandb_tags': ['exp034', 'imu_only', 'afno', 'fourier_neural_operator', 'fft_mixer', 'residual_se_cnn', 'human_normalization', 'demographics', 'soft_f1_acls', 'mish']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 30, 'min_delta': 0.0001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp034', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/17/2025 10:24:49 PM INFO __main__: Starting training for fold 0
08/17/2025 10:26:29 PM INFO __main__: Using input_dim=20 (HN features: False)
08/17/2025 10:33:06 PM INFO __main__: Loading best model from: ../../../outputs/exp034/fold_0/version_1/checkpoints/epoch-143-val_cmi_score-0.7634.ckpt
08/17/2025 10:33:08 PM INFO __main__: Fold 0 results: {'fold': 0, 'val_loss': 1.0890907049179077, 'val_cmi_score': 0.7634223103523254, 'val_multiclass_loss': 1.3664031028747559, 'val_binary_loss': 0.2279968112707138, 'best_model_path': '../../../outputs/exp034/fold_0/version_1/checkpoints/epoch-143-val_cmi_score-0.7634.ckpt'}
08/17/2025 10:33:08 PM INFO __main__: Starting training for fold 1
08/17/2025 10:34:49 PM INFO __main__: Using input_dim=20 (HN features: False)
08/17/2025 10:41:12 PM INFO __main__: Loading best model from: ../../../outputs/exp034/fold_1/version_0/checkpoints/epoch-144-val_cmi_score-0.7365.ckpt
08/17/2025 10:41:14 PM INFO __main__: Fold 1 results: {'fold': 1, 'val_loss': 1.3429750204086304, 'val_cmi_score': 0.7364514470100403, 'val_multiclass_loss': 1.7535345554351807, 'val_binary_loss': 0.22612673044204712, 'best_model_path': '../../../outputs/exp034/fold_1/version_0/checkpoints/epoch-144-val_cmi_score-0.7365.ckpt'}
08/17/2025 10:41:14 PM INFO __main__: Starting training for fold 2
08/17/2025 10:42:57 PM INFO __main__: Using input_dim=20 (HN features: False)
08/17/2025 10:50:30 PM INFO __main__: Loading best model from: ../../../outputs/exp034/fold_2/version_0/checkpoints/epoch-169-val_cmi_score-0.7700.ckpt
08/17/2025 10:50:33 PM INFO __main__: Fold 2 results: {'fold': 2, 'val_loss': 1.1312823295593262, 'val_cmi_score': 0.7699732780456543, 'val_multiclass_loss': 1.4439630508422852, 'val_binary_loss': 0.18091315031051636, 'best_model_path': '../../../outputs/exp034/fold_2/version_0/checkpoints/epoch-169-val_cmi_score-0.7700.ckpt'}
08/17/2025 10:50:33 PM INFO __main__: Starting training for fold 3
08/17/2025 10:52:18 PM INFO __main__: Using input_dim=20 (HN features: False)
08/17/2025 10:58:58 PM INFO __main__: Loading best model from: ../../../outputs/exp034/fold_3/version_0/checkpoints/epoch-143-val_cmi_score-0.7517.ckpt
08/17/2025 10:59:01 PM INFO __main__: Fold 3 results: {'fold': 3, 'val_loss': 1.2136200666427612, 'val_cmi_score': 0.7516767978668213, 'val_multiclass_loss': 1.580493688583374, 'val_binary_loss': 0.1969814896583557, 'best_model_path': '../../../outputs/exp034/fold_3/version_0/checkpoints/epoch-143-val_cmi_score-0.7517.ckpt'}
08/17/2025 10:59:01 PM INFO __main__: Starting training for fold 4
08/17/2025 11:00:42 PM INFO __main__: Using input_dim=20 (HN features: False)
