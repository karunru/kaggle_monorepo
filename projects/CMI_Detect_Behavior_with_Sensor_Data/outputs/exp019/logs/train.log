08/14/2025 12:40:22 AM INFO __main__: Starting cross-validation training
08/14/2025 12:40:22 AM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp019', 'name': 'exp019_bert_integration', 'description': 'BERT integration for enhanced temporal feature extraction', 'tags': ['bert', 'attention', 'transformer', 'squeezeformer', 'pytorch_lightning', 'physics_features']}, 'paths': {'output_dir': '../../../outputs/exp019'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': True, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp019', 'wandb_tags': ['exp019', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp019', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/14/2025 12:40:22 AM INFO __main__: Starting training for fold 0
08/14/2025 12:59:35 AM INFO __main__: Starting cross-validation training
08/14/2025 12:59:35 AM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp019', 'name': 'exp019_bert_integration', 'description': 'BERT integration for enhanced temporal feature extraction', 'tags': ['bert', 'attention', 'transformer', 'squeezeformer', 'pytorch_lightning', 'physics_features']}, 'paths': {'output_dir': '../../../outputs/exp019'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': True, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp019', 'wandb_tags': ['exp019', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp019', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/14/2025 12:59:35 AM INFO __main__: Starting training for fold 0
08/14/2025 01:16:50 AM INFO __main__: Loading best model from: ../../../outputs/exp019/fold_0/version_1/checkpoints/epoch-29-val_cmi_score-0.7453.ckpt
08/14/2025 01:16:54 AM INFO __main__: Fold 0 results: {'fold': 0, 'val_loss': 0.759354829788208, 'val_cmi_score': 0.7453452348709106, 'val_multiclass_loss': 1.375478982925415, 'val_binary_loss': 0.1432305872440338, 'best_model_path': '../../../outputs/exp019/fold_0/version_1/checkpoints/epoch-29-val_cmi_score-0.7453.ckpt'}
08/14/2025 01:16:54 AM INFO __main__: Starting training for fold 1
08/14/2025 01:38:25 AM INFO __main__: Loading best model from: ../../../outputs/exp019/fold_1/version_0/checkpoints/epoch-42-val_cmi_score-0.7411.ckpt
08/14/2025 01:38:29 AM INFO __main__: Fold 1 results: {'fold': 1, 'val_loss': 0.9724438190460205, 'val_cmi_score': 0.74111008644104, 'val_multiclass_loss': 1.7543925046920776, 'val_binary_loss': 0.19049493968486786, 'best_model_path': '../../../outputs/exp019/fold_1/version_0/checkpoints/epoch-42-val_cmi_score-0.7411.ckpt'}
08/14/2025 01:38:29 AM INFO __main__: Starting training for fold 2
08/14/2025 02:05:49 AM INFO __main__: Loading best model from: ../../../outputs/exp019/fold_2/version_0/checkpoints/epoch-61-val_cmi_score-0.7542.ckpt
08/14/2025 02:05:53 AM INFO __main__: Fold 2 results: {'fold': 2, 'val_loss': 1.1334822177886963, 'val_cmi_score': 0.7541507482528687, 'val_multiclass_loss': 2.0569658279418945, 'val_binary_loss': 0.20999890565872192, 'best_model_path': '../../../outputs/exp019/fold_2/version_0/checkpoints/epoch-61-val_cmi_score-0.7542.ckpt'}
08/14/2025 02:05:53 AM INFO __main__: Starting training for fold 3
08/14/2025 02:26:19 AM INFO __main__: Loading best model from: ../../../outputs/exp019/fold_3/version_0/checkpoints/epoch-37-val_cmi_score-0.7540.ckpt
08/14/2025 02:26:23 AM INFO __main__: Fold 3 results: {'fold': 3, 'val_loss': 0.795876681804657, 'val_cmi_score': 0.7539991140365601, 'val_multiclass_loss': 1.5077811479568481, 'val_binary_loss': 0.08397237956523895, 'best_model_path': '../../../outputs/exp019/fold_3/version_0/checkpoints/epoch-37-val_cmi_score-0.7540.ckpt'}
08/14/2025 02:26:23 AM INFO __main__: Starting training for fold 4
08/14/2025 02:47:53 AM INFO __main__: Loading best model from: ../../../outputs/exp019/fold_4/version_0/checkpoints/epoch-42-val_cmi_score-0.7668.ckpt
08/14/2025 02:47:57 AM INFO __main__: Fold 4 results: {'fold': 4, 'val_loss': 0.8619872331619263, 'val_cmi_score': 0.7668256163597107, 'val_multiclass_loss': 1.5466588735580444, 'val_binary_loss': 0.17731554806232452, 'best_model_path': '../../../outputs/exp019/fold_4/version_0/checkpoints/epoch-42-val_cmi_score-0.7668.ckpt'}
08/14/2025 02:47:57 AM INFO __main__: Cross-validation completed
08/14/2025 02:47:57 AM INFO __main__: Mean CV Loss: 0.9046 ± 0.1354
08/14/2025 02:47:57 AM INFO __main__: Mean CV CMI Score: 0.7523 ± 0.0088
08/14/2025 02:47:57 AM INFO __main__: Results saved to: ../../../outputs/exp019/cv_results.csv
08/14/2025 02:47:57 AM INFO __main__: CV results logged to WandB
08/14/2025 09:35:48 PM INFO __main__: Starting cross-validation training
08/14/2025 09:35:48 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp019', 'name': 'exp019_bert_integration', 'description': 'BERT integration for enhanced temporal feature extraction', 'tags': ['bert', 'attention', 'transformer', 'squeezeformer', 'pytorch_lightning', 'physics_features']}, 'paths': {'output_dir': '../../../outputs/exp019'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': True, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp019', 'wandb_tags': ['exp019', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp019', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/14/2025 09:35:48 PM INFO __main__: Starting training for fold 0
08/14/2025 09:37:09 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 245, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 129, in train_single_fold
    data_module.setup("fit")
    ~~~~~~~~~~~~~~~~~^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 1350, in setup
    self.train_dataset = IMUDataset(
                         ~~~~~~~~~~^
        train_sequence_ids,
        ^^^^^^^^^^^^^^^^^^^
    ...<7 lines>...
        handedness_flip_prob=self.config.augmentation.handedness_flip_prob,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 637, in __init__
    self._preprocess_data()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 753, in _preprocess_data
    self.sequence_data = self._preprocess_data_vectorized_with_mask()
                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 920, in _preprocess_data_vectorized_with_mask
    df_with_physics = self._add_physics_features(self.df)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 811, in _add_physics_features
    df_with_advanced = self._add_advanced_physics_features(df_with_physics)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 908, in _add_advanced_physics_features
    ).collect()
      ~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/_utils/deprecation.py", line 97, in wrapper
    return function(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/lazyframe/opt_flags.py", line 330, in wrapper
    return function(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/lazyframe/frame.py", line 2335, in collect
    return wrap_df(ldf.collect(engine, callback))
                   ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
polars.exceptions.InvalidOperationError: window expression not allowed in aggregation
08/14/2025 09:43:00 PM INFO __main__: Starting cross-validation training
08/14/2025 09:43:00 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp019', 'name': 'exp019_bert_integration', 'description': 'BERT integration for enhanced temporal feature extraction', 'tags': ['bert', 'attention', 'transformer', 'squeezeformer', 'pytorch_lightning', 'physics_features']}, 'paths': {'output_dir': '../../../outputs/exp019'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': True, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp019', 'wandb_tags': ['exp019', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp019', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/14/2025 09:43:00 PM INFO __main__: Starting training for fold 0
08/14/2025 09:44:18 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 245, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 129, in train_single_fold
    data_module.setup("fit")
    ~~~~~~~~~~~~~~~~~^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 1350, in setup
    self.train_dataset = IMUDataset(
                         ~~~~~~~~~~^
        train_sequence_ids,
        ^^^^^^^^^^^^^^^^^^^
    ...<7 lines>...
        handedness_flip_prob=self.config.augmentation.handedness_flip_prob,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 637, in __init__
    self._preprocess_data()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 753, in _preprocess_data
    self.sequence_data = self._preprocess_data_vectorized_with_mask()
                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 920, in _preprocess_data_vectorized_with_mask
    df_with_physics = self._add_physics_features(self.df)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 811, in _add_physics_features
    df_with_advanced = self._add_advanced_physics_features(df_with_physics)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/dataset.py", line 908, in _add_advanced_physics_features
    ).collect()
      ~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/_utils/deprecation.py", line 97, in wrapper
    return function(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/lazyframe/opt_flags.py", line 330, in wrapper
    return function(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/polars/lazyframe/frame.py", line 2335, in collect
    return wrap_df(ldf.collect(engine, callback))
                   ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
polars.exceptions.InvalidOperationError: window expression not allowed in aggregation
08/14/2025 10:32:33 PM INFO __main__: Starting cross-validation training
08/14/2025 10:32:33 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp019', 'name': 'exp019_bert_integration', 'description': 'BERT integration for enhanced temporal feature extraction', 'tags': ['bert', 'attention', 'transformer', 'squeezeformer', 'pytorch_lightning', 'physics_features']}, 'paths': {'output_dir': '../../../outputs/exp019'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0003, 'weight_decay': 1e-05, 'gradient_clip_val': 1.0, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': True, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp019', 'wandb_tags': ['exp019', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp019', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/14/2025 10:32:33 PM INFO __main__: Starting training for fold 0
08/14/2025 10:36:18 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 245, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/train.py", line 168, in train_single_fold
    trainer.fit(model, data_module)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
    ~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
    ~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/model.py", line 878, in validation_step
    multiclass_logits, binary_logits = self(imu, attention_mask, demographics)
                                       ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp020/model.py", line 781, in forward
    x = self.input_projection(x)  # [batch, seq_len, d_model]
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [128, 61] but got: [128, 16].
