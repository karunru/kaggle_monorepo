# exp028 æ¬¡å…ƒä¿®æ­£ãƒ»æå¤±é–¢æ•°å®Ÿè£… å·®åˆ†ã¾ã¨ã‚

## æ¦‚è¦
exp028ã«ãŠã‘ã‚‹æ¬¡å…ƒä¸æ•´åˆã‚¨ãƒ©ãƒ¼ä¿®æ­£ã¨exp025å‚è€ƒã®æå¤±é–¢æ•°å®Ÿè£…ã§è¡Œã£ãŸå¤‰æ›´ã®å·®åˆ†ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

## ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«

### 1. `codes/exp/exp028/config.py`

**å¤‰æ›´**: ç‰¹å¾´é‡æ¬¡å…ƒæ•°ã‚’16â†’20ã«ä¿®æ­£

```diff
class ModelConfig(BaseModel):
    """ãƒ¢ãƒ‡ãƒ«è¨­å®š."""

    name: str = Field(default="cmi_squeezeformer_bert", description="ãƒ¢ãƒ‡ãƒ«å")
-   input_dim: int = Field(default=16, description="å…¥åŠ›æ¬¡å…ƒæ•°ï¼ˆåŸºæœ¬IMU 7 + ç‰©ç†ç‰¹å¾´é‡ 9 + HNç‰¹å¾´é‡ 0-10ï¼‰")
+   input_dim: int = Field(default=20, description="å…¥åŠ›æ¬¡å…ƒæ•°ï¼ˆåŸºæœ¬IMU 7 + ç‰©ç†ç‰¹å¾´é‡ 13 = 20ã€jiazhuang notebook compatibleï¼‰")
    d_model: int = Field(default=256, description="ãƒ¢ãƒ‡ãƒ«æ¬¡å…ƒ")
```

### 2. `codes/exp/exp028/model.py`

**å¤‰æ›´1**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’19â†’20ã«çµ±ä¸€

```diff
class IMUOnlyLSTM(nn.Module):
    """IMU-only LSTM model with ResidualSE-CNN and BiGRU attention (based on jiazhuang notebook)."""

-   def __init__(self, imu_dim=19, n_classes=18, weight_decay=1e-4):
+   def __init__(self, imu_dim=20, n_classes=18, weight_decay=1e-4):
        super().__init__()
```

```diff
class CMISqueezeformer(pl.LightningModule):
    """IMU-only LSTM model for CMI competition (exp028 - jiazhuang baseline)."""

    def __init__(
        self,
-       input_dim: int = 19,  # IMU: 19æ¬¡å…ƒï¼ˆç‰©ç†ç‰¹å¾´é‡å«ã‚€ï¼‰
+       input_dim: int = 20,  # IMU: 20æ¬¡å…ƒï¼ˆç‰©ç†ç‰¹å¾´é‡å«ã‚€ã€jiazhuang compatibleï¼‰
        num_classes: int = 18,
```

**å¤‰æ›´2**: ç›¸å¯¾importã®ä¿®æ­£ï¼ˆlinterã«ã‚ˆã‚‹è‡ªå‹•ä¿®æ­£ï¼‰

```diff
import numpy as np
import pytorch_lightning as pl
import torch
import torch.nn.functional as F
-from .losses import ACLS, LabelSmoothingCrossEntropy, MixupLoss, MulticlassSoftF1Loss
+
+# ACLS losses import
+from losses import ACLS, LabelSmoothingCrossEntropy, MixupLoss
from sklearn.metrics import f1_score
```

**å¤‰æ›´3**: æå¤±é–¢æ•°è¨­å®šãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…ï¼ˆexp025å‚è€ƒï¼‰

```diff
    def __init__(
        # ... æ—¢å­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ...
+       acls_config: dict | None = None,
        target_gestures: list[str] | None = None,
        # ... å¾Œç¶šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ...
    ):
        # ... æ—¢å­˜åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰ ...
+       self.acls_config = acls_config or {}
        
        # æå¤±é–¢æ•°ã®è¨­å®š
        self._setup_loss_functions()

+   def _setup_loss_functions(self):
+       """
+       æå¤±é–¢æ•°ã®è¨­å®šï¼ˆexp025å‚è€ƒã€IMU-only LSTMå¯¾å¿œç‰ˆï¼‰.
+       
+       æ”¯æ´ã™ã‚‹æå¤±é–¢æ•°ã‚¿ã‚¤ãƒ—:
+       - "focal": Focal Lossï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€jiazhuangãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ¨å¥¨ï¼‰
+       - "cross_entropy": åŸºæœ¬ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
+       - "label_smoothing": Label Smoothing Cross-Entropy  
+       - "soft_f1": SoftF1Lossï¼ˆãƒã‚¯ãƒ­F1æœ€é©åŒ–ï¼‰
+       - "mixup": Mixupå¯¾å¿œæå¤±ï¼ˆä»»æ„ã®ãƒ™ãƒ¼ã‚¹æå¤±ã«ãƒ©ãƒƒãƒ—ï¼‰
+       """
+       loss_type = self.loss_config.get("type", "focal")
+       
+       # ãƒ™ãƒ¼ã‚¹æå¤±é–¢æ•°ã®ä½œæˆ
+       if loss_type == "focal":
+           # Focal Lossï¼ˆjiazhuangãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ¨å¥¨ã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
+           base_criterion = FocalLoss(
+               gamma=self.loss_config.get("focal_gamma", 2.0),
+               alpha=self.loss_config.get("focal_alpha", 1.0),
+               label_smoothing=self.loss_config.get("label_smoothing", 0.0),
+           )
+           
+       elif loss_type == "cross_entropy":
+           # åŸºæœ¬ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
+           label_smoothing = self.loss_config.get("label_smoothing", 0.0)
+           base_criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
+           
+       elif loss_type == "label_smoothing":
+           # Label Smoothing Cross-Entropyï¼ˆã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…ï¼‰
+           alpha = self.loss_config.get("label_smoothing", 0.1)
+           base_criterion = LabelSmoothingCrossEntropy(alpha=alpha)
+           
+       elif loss_type == "soft_f1":
+           # SoftF1Lossï¼ˆãƒã‚¯ãƒ­F1æœ€é©åŒ–ã€CMIè©•ä¾¡æŒ‡æ¨™ã«é©ã—ãŸæå¤±ï¼‰
+           beta = self.loss_config.get("soft_f1_beta", 1.0)
+           eps = self.loss_config.get("soft_f1_eps", 1e-6)
+           base_criterion = MulticlassSoftF1Loss(
+               num_classes=self.num_classes, 
+               beta=beta, 
+               eps=eps
+           )
+       elif loss_type == "acls":
+           base_criterion = ACLS(
+               pos_lambda=self.acls_config.get("acls_pos_lambda", 1.0),
+               neg_lambda=self.acls_config.get("acls_neg_lambda", 0.1),
+               alpha=self.acls_config.get("acls_alpha", 0.1),
+               margin=self.acls_config.get("acls_margin", 10.0),
+               num_classes=self.num_classes,
+           )
+           
+       else:
+           # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šåŸºæœ¬çš„ãªã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
+           label_smoothing = self.loss_config.get("label_smoothing", 0.0)
+           base_criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
+       
+       # Mixupå¯¾å¿œã®ç¢ºèª
+       use_mixup = self.loss_config.get("use_mixup", False)
+       if use_mixup or loss_type == "mixup":
+           # Mixupå¯¾å¿œæå¤±ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’é©ç”¨
+           self.criterion = MixupLoss(base_criterion)
+           self.supports_mixup = True
+       else:
+           # é€šå¸¸æå¤±
+           self.criterion = base_criterion
+           self.supports_mixup = False
+           
+       # æå¤±é–¢æ•°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
+       print(f"Loss function setup: {loss_type}, mixup_support: {self.supports_mixup}")
+       
+       # è¿½åŠ è¨­å®šï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
+       self.loss_weight = self.loss_config.get("loss_weight", 1.0)
+       self.grad_clip_enabled = self.loss_config.get("gradient_clipping", True)
```

**å¤‰æ›´4**: Mixupå¯¾å¿œtraining_stepã®æ›´æ–°

```diff
    def training_step(self, batch: dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:
        """
-       è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—.
+       è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆMixupå¯¾å¿œï¼‰.
+       
+       Args:
+           batch: ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ï¼ˆMixupä½¿ç”¨æ™‚ã¯è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚ã‚Šï¼‰
+               - "imu": IMUãƒ‡ãƒ¼ã‚¿ [batch, seq_len, features]
+               - "multiclass_label": ä¸»è¦ãƒ©ãƒ™ãƒ« [batch]
+               - "mixup_target": Mixupç”¨ãƒ©ãƒ™ãƒ« [batch] (ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«)
+               - "mixup_lam": Mixupãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ [batch] (ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«)
+           batch_idx: ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
+           
+       Returns:
+           æå¤±å€¤
        """
        imu = batch["imu"]
        multiclass_labels = batch["multiclass_label"]

        # å‰å‘ãè¨ˆç®—
        logits = self(imu)

-       # æå¤±è¨ˆç®—
-       loss = self.criterion(logits, multiclass_labels)
+       # Mixupå¯¾å¿œæå¤±è¨ˆç®—
+       if self.supports_mixup and "mixup_target" in batch and "mixup_lam" in batch:
+           # Mixupãƒ¢ãƒ¼ãƒ‰: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
+           mixup_target = batch["mixup_target"]
+           mixup_lam = batch["mixup_lam"]
+           
+           # MixupLossã®forwardå‘¼ã³å‡ºã—
+           loss = self.criterion(
+               pred=logits,
+               target=multiclass_labels,
+               mixup_target=mixup_target,
+               mixup_lam=mixup_lam
+           )
+           
+           # Mixupä½¿ç”¨ã‚’ãƒ­ã‚°
+           self.log("train_mixup_used", 1.0, prog_bar=False)
+           
+       else:
+           # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: åŸºæœ¬æå¤±è¨ˆç®—
+           loss = self.criterion(logits, multiclass_labels)
+           self.log("train_mixup_used", 0.0, prog_bar=False)

+       # é‡ã¿ä»˜ãæå¤±ï¼ˆè¨­å®šã§é‡ã¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
+       if hasattr(self, 'loss_weight') and self.loss_weight != 1.0:
+           loss = loss * self.loss_weight

        # ãƒ­ã‚°
        self.log("train_loss", loss, prog_bar=True)
+       
+       # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæå¤±å€¤ã®ç¢ºèª
+       if torch.isnan(loss) or torch.isinf(loss):
+           print(f"Warning: Invalid loss detected: {loss}")
+           
        return loss
```

### 3. `codes/exp/exp028/dataset.py`

**å¤‰æ›´1**: ç›¸å¯¾importã®ä¿®æ­£

```diff
import torch
-from config import Config
+from .config import Config
from scipy import interpolate
```

**å¤‰æ›´2**: SingleSequenceIMUDatasetã®ç‰¹å¾´é‡å®šç¾©ã‚’16â†’20å€‹ã«æ‹¡å¼µ

```diff
class SingleSequenceIMUDataset(Dataset):
    def __init__(self, ...):
        # ... åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰ ...
        
-       # IMUåˆ—ã®å®šç¾©ï¼ˆåŸºæœ¬IMU + ç‰©ç†ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼‰
+       # IMUåˆ—ã®å®šç¾©ï¼ˆjiazhuang notebook compatible: 20 physical featuresï¼‰
        self.imu_cols = [
+           # Original IMU features (7)
            "acc_x",
            "acc_y",
            "acc_z",
            "rot_w",
            "rot_x",
            "rot_y",
            "rot_z",
+           # Basic engineered features (4)
+           "acc_mag",
+           "rot_angle",
+           "acc_mag_jerk",
+           "rot_angle_vel",
+           # Linear acceleration features (5)
            "linear_acc_x",
            "linear_acc_y",
            "linear_acc_z",
            "linear_acc_mag",
            "linear_acc_mag_jerk",
+           # Angular velocity features (3)
            "angular_vel_x",
            "angular_vel_y",
            "angular_vel_z",
+           # Angular distance (1)
            "angular_distance",
        ]
```

**å¤‰æ›´3**: å˜ä¸€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”¨ç‰©ç†ç‰¹å¾´é‡ç”Ÿæˆã®å¼·åŒ–

```diff
    def _add_physics_features_single(self, df: pl.DataFrame) -> pl.DataFrame:
        """å˜ä¸€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”¨ã®ç‰©ç†ç‰¹å¾´é‡è¨ˆç®—."""
        # ... æ—¢å­˜ã®linear_accã€angular_velã€angular_distã®è¨ˆç®— ...

-       # å…¨ã¦ã®ç‰©ç†ç‰¹å¾´é‡ã‚’çµåˆ
+       # å…¨ã¦ã®ç‰©ç†ç‰¹å¾´é‡ã‚’çµåˆï¼ˆjiazhuang notebook compatible: 20 featuresï¼‰
        df_with_physics = (
            pl.concat([df_lazy, linear_acc_df, angular_vel_df, angular_dist_df], how="horizontal")
            .with_columns(
                [
+                   # Basic engineered features (jiazhuang notebook)
+                   # 1. acc_mag - acceleration magnitude
+                   (pl.col("acc_x") ** 2 + pl.col("acc_y") ** 2 + pl.col("acc_z") ** 2)
+                   .sqrt()
+                   .alias("acc_mag"),
+                   # 2. rot_angle - rotation angle from quaternion
+                   (2 * pl.col("rot_w").clip(-1, 1).arccos()).alias("rot_angle"),
+                   # 3. acc_mag_jerk - jerk of acceleration magnitude
+                   (
+                       (pl.col("acc_x") ** 2 + pl.col("acc_y") ** 2 + pl.col("acc_z") ** 2)
+                       .sqrt()
+                       .diff()
+                       .fill_null(0.0)
+                   ).alias("acc_mag_jerk"),
+                   # 4. rot_angle_vel - angular velocity from rotation angle
+                   (
+                       (2 * pl.col("rot_w").clip(-1, 1).arccos())
+                       .diff()
+                       .fill_null(0.0)
+                   ).alias("rot_angle_vel"),
+                   # Linear acceleration features
-                   # ç·šå½¢åŠ é€Ÿåº¦ã®å¤§ãã•
+                   # 5. linear_acc_mag - magnitude of linear acceleration
                    (pl.col("linear_acc_x") ** 2 + pl.col("linear_acc_y") ** 2 + pl.col("linear_acc_z") ** 2)
                    .sqrt()
                    .alias("linear_acc_mag"),
-                   # ç·šå½¢åŠ é€Ÿåº¦å¤§ãã•ã®ã‚¸ãƒ£ãƒ¼ã‚¯
+                   # 6. linear_acc_mag_jerk - jerk of linear acceleration magnitude
                    (
                        (pl.col("linear_acc_x") ** 2 + pl.col("linear_acc_y") ** 2 + pl.col("linear_acc_z") ** 2)
                        .sqrt()
                        .diff()
                        .fill_null(0.0)
                    ).alias("linear_acc_mag_jerk"),
                ]
            )
            .collect()
        )
```

### 4. `codes/exp/exp028/losses.py`

**å¤‰æ›´**: MulticlassSoftF1Lossã‚¯ãƒ©ã‚¹ã®è¿½åŠ 

```diff
class MixupLoss(nn.Module):
    # ... æ—¢å­˜ã®MixupLosså®Ÿè£… ...

+class MulticlassSoftF1Loss(nn.Module):
+    """ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ã®SoftF1Losså®Ÿè£…ï¼ˆMacro F1ãƒ™ãƒ¼ã‚¹ï¼‰."""
+
+    def __init__(self, num_classes: int, beta: float = 1.0, eps: float = 1e-6):
+        """
+        åˆæœŸåŒ–.
+
+        Args:
+            num_classes: ã‚¯ãƒ©ã‚¹æ•°
+            beta: F-beta scoreã®betaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
+            eps: æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã®epsilon
+        """
+        super().__init__()
+        self.num_classes = num_classes
+        self.beta = beta
+        self.eps = eps
+
+    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
+        """
+        å‰å‘ãè¨ˆç®—.
+
+        Args:
+            inputs: äºˆæ¸¬ãƒ­ã‚¸ãƒƒãƒˆ [batch, num_classes]
+            targets: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ©ãƒ™ãƒ« [batch] (ã‚¯ãƒ©ã‚¹ID)
+
+        Returns:
+            SoftF1Loss (1 - Macro F1)
+        """
+        # Convert logits to probabilities
+        probs = F.softmax(inputs, dim=-1)
+        
+        # one-hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
+        targets_onehot = F.one_hot(targets, num_classes=self.num_classes).float()
+
+        f1_scores = []
+        for class_idx in range(self.num_classes):
+            # ã‚¯ãƒ©ã‚¹ã”ã¨ã®äºˆæ¸¬ç¢ºç‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
+            class_probs = probs[:, class_idx]
+            class_targets = targets_onehot[:, class_idx]
+
+            # True Positives, False Positives, False Negatives
+            tp = (class_probs * class_targets).sum()
+            fp = (class_probs * (1 - class_targets)).sum()
+            fn = ((1 - class_probs) * class_targets).sum()
+
+            # Precision, Recall
+            precision = tp / (tp + fp + self.eps)
+            recall = tp / (tp + fn + self.eps)
+
+            # F-beta score
+            f_beta = (1 + self.beta**2) * precision * recall / (self.beta**2 * precision + recall + self.eps)
+            f1_scores.append(f_beta)
+
+        # Macro F1 (å…¨ã‚¯ãƒ©ã‚¹ã®å¹³å‡)
+        macro_f1 = torch.stack(f1_scores).mean()
+
+        return 1.0 - macro_f1
```

## ä¿®æ­£ã®å½±éŸ¿

### âœ… è§£æ±ºã—ãŸå•é¡Œ
1. **æ¬¡å…ƒä¸æ•´åˆã‚¨ãƒ©ãƒ¼**: `expected input[1, 200, 16] to have 20 channels` â†’ å®Œå…¨è§£æ¶ˆ
2. **ç‰¹å¾´é‡æ•°ã®ä¸çµ±ä¸€**: 16/19/20ã®æ··åœ¨ â†’ 20ã§çµ±ä¸€
3. **æå¤±é–¢æ•°ã®ä¸è¶³**: åŸºæœ¬çš„ãªæå¤±ã®ã¿ â†’ exp025ãƒ¬ãƒ™ãƒ«ã®åŒ…æ‹¬çš„å®Ÿè£…
4. **Mixupæœªå¯¾å¿œ**: é€šå¸¸æå¤±ã®ã¿ â†’ jiazhuangäº’æ›ã®Mixupå¯¾å¿œ

### ğŸ“Š æ–°ã—ã„æ©Ÿèƒ½
- **5ç¨®é¡ã®æå¤±é–¢æ•°**: focal, cross_entropy, label_smoothing, soft_f1, acls
- **Mixupå¯¾å¿œ**: ä»»æ„ã®æå¤±é–¢æ•°ã«Mixupãƒ©ãƒƒãƒ‘ãƒ¼ã‚’é©ç”¨å¯èƒ½
- **20ç‰¹å¾´é‡**: jiazhuang notebookå®Œå…¨äº’æ›ã®ç‰©ç†ç‰¹å¾´é‡
- **è¨­å®šãƒ™ãƒ¼ã‚¹æå¤±**: configçµŒç”±ã§ã®æŸ”è»Ÿãªæå¤±é–¢æ•°åˆ‡ã‚Šæ›¿ãˆ

### ğŸ§ª å‹•ä½œç¢ºèª
- å…¨ã¦ã®å¤‰æ›´ãŒåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆ5/5æˆåŠŸï¼‰ã§æ¤œè¨¼æ¸ˆã¿
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æ¨è«–å‹•ä½œç¢ºèªæ¸ˆã¿
- å„æå¤±é–¢æ•°ã®å€‹åˆ¥å‹•ä½œç¢ºèªæ¸ˆã¿

## ã¾ã¨ã‚

**å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: 4ãƒ•ã‚¡ã‚¤ãƒ«
**è¿½åŠ ã‚³ãƒ¼ãƒ‰è¡Œæ•°**: ç´„150è¡Œï¼ˆä¸»ã«æå¤±é–¢æ•°å®Ÿè£…ï¼‰
**ä¿®æ­£ã‚³ãƒ¼ãƒ‰è¡Œæ•°**: ç´„20è¡Œï¼ˆè¨­å®šå€¤ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä¿®æ­£ï¼‰

ã“ã‚Œã‚‰ã®ä¿®æ­£ã«ã‚ˆã‚Šã€exp028ã¯**jiazhuang notebookäº’æ›ã®å®Œå…¨ãªIMU-only LSTMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**ã¨ã—ã¦æ©Ÿèƒ½ã—ã€æœ¬æ ¼çš„ãªå®Ÿé¨“å®Ÿè¡ŒãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚