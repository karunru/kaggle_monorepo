## **MiniRocket**

A Very Fast (Almost) Deterministic Transform for Time Series Classification



Geoffrey I. Webb
geoff.webb@monash.edu
Monash University
Melbourne, Australia



Angus Dempster
angus.dempster1@monash.edu
Monash University
Melbourne, Australia


**ABSTRACT**



Daniel F. Schmidt

daniel.schmidt@monash.edu
Monash University
Melbourne, Australia



9 8 7 6 5 4 3 2 1



Rocket achieves state-of-the-art accuracy for time series classification with a fraction of the computational expense of most existing
methods by transforming input time series using random convolutional kernels, and using the transformed features to train a linear
classifier. We reformulate Rocket into a new method, MiniRocket.
MiniRocket is up to 75 times faster than Rocket on larger datasets,
and almost deterministic (and optionally, fully deterministic), while
maintaining essentially the same accuracy. Using this method, it
is possible to train and test a classifier on all of 109 datasets from
the UCR archive to state-of-the-art accuracy in under 10 minutes.
MiniRocket is significantly faster than any other method of comparable accuracy (including Rocket), and significantly more accurate
than any other method of remotely similar computational expense.


**CCS CONCEPTS**


- **Computing methodologies** â†’ **Machine learning** ; - **Informa-**
**tion systems** â†’ **Data mining** .


**KEYWORDS**


scalable; time series classification; convolution; transform


**ACM Reference Format:**
Angus Dempster, Daniel F. Schmidt, and Geoffrey I. Webb. 2021. MiniRocket:
A Very Fast (Almost) Deterministic Transform for Time Series Classification.
In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery_
_and Data Mining (KDD â€™21), August 14â€“18, 2021, Virtual Event, Singapore._
[ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3447548.3467231](https://doi.org/10.1145/3447548.3467231)


**1** **INTRODUCTION**


Until recently, the most accurate methods for time series classification were limited by high computational complexity. While there
have been considerable advances in recent years, computational
complexity and a lack of scalability remain persistent problems.
Rocket [ 8 ] achieves state-of-the-art accuracy with a fraction of
the computational expense of any method of comparable accuracy
by transforming input time series using random convolutional kernels, and using the transformed features to train a linear classifier.
We show that it is possible to reformulate Rocket, making it up to
75 times faster on larger datasets, and making it almost entirely deterministic (and optionally, with additional computational expense,


_KDD â€™21, August 14â€“18, 2021, Virtual Event, Singapore_
Â© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
This is the authorâ€™s version of the work. It is posted here for your personal use. Not
for redistribution. The definitive Version of Record was published in _Proceedings of_
_the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD â€™21),_
_August 14â€“18, 2021, Virtual Event, Singapore_ [, https://doi.org/10.1145/3447548.3467231.](https://doi.org/10.1145/3447548.3467231)



10 [0]


10 [âˆ’1]


10 [âˆ’1] 10 [0] 10 [1] 10 [2] 10 [3]


Rocket


**Figure 2: Transform time for MiniRocket versus Rocket**
**for the same 109 datasets from the UCR archive.**


fully deterministic), while maintaining essentially the same accuracy. We call this method MiniRocket (for **MINI** mally **R** and **O** m
**C** onvolutional **KE** rnel **T** ransform).
Like Rocket, MiniRocket transforms input time series using
convolutional kernels, and uses the transformed features to train
a linear classifier. However, unlike Rocket, MiniRocket uses a
small, fixed set of kernels, and is almost entirely deterministic.
MiniRocket maintains the two most important aspects of Rocket:
dilation and PPV, i.e., â€˜proportion of positive valuesâ€™ pooling [ 8 ].
MiniRocket exploits various properties of the kernels, and of PPV,
in order to massively reduce the time required for the transform.
MiniRocket demonstrates that, while random convolutional kernels are highly effective, it is possible to achieve essentially the same
accuracy using a mostly-deterministic and much faster procedure.
Figure 1 shows the mean rank of MiniRocket in terms of accuracy versus other state-of-the-art methods over 30 resamples of 109
datasets from the UCR archive of benchmark time series [ 7 ]. On



cBOSS
ProximityForest

CIF
TDE
InceptionTime



HIVE-COTE/TDE
TS-CHIEF
**MiniRocket**
Rocket



**Figure 1: Mean rank of MiniRocket in terms of accu-**
**racy versus other SOTA methods over 30 resamples of 109**
**datasets from the UCR archive.**


Transform Time, Seconds


10 [3]



10 [2]


10 [1]



MiniRocket is 10x faster


MiniRocket is 100x faster


average, MiniRocket is marginally more accurate than Rocket,
and slightly less accurate than the most accurate current methods.
Figure 2 shows total transform time (training and test) for
MiniRocket versus Rocket, for the same 109 datasets. On average, MiniRocket is more than 30 times faster than Rocket (the
advantage is even greater for larger datasets: see Section 4.2). Restricted to a single CPU core, total compute time for Rocket over
all 109 datasets is 2 hours 2 minutes (1h 55m transform time), versus just 8 minutes for MiniRocket (2m 30s transform time). To
put this in context, total compute time for MiniRocket for all 109
datasets is less than the compute time for Rocket for just one of
those datasets. (Compute times are averages over 30 resamples, run
on a cluster using Intel Xeon E5-2680 v3/4 and Xeon Gold 6150
CPUs, restricted to a single CPU core per dataset per resample.)
While only broadly comparable due to hardware and software
differences, total compute time for the same 109 datasets using
a single CPU thread is approximately 13 hours for cBOSS, more
than a day for CIF, more than two days for TDE, approximately a
week for Proximity Forest, more than two weeks for HIVE-COTE,
and several weeks for TS-CHIEF [ 2, 27, 28 ]. Total compute time for
InceptionTime (using GPUs, and for the original training/test splits
rather than resamples) is more than 4 days [16].
MiniRocket represents a significant advance in accuracy relative to computational cost. MiniRocket is significantly faster
than any other method of comparable accuracy (including Rocket),
and significantly more accurate than any other method of even
roughly-similar computational expense.
The rest of this paper is structured as follows. In Section 2, we
review relevant related work. In Section 3, we detail the changes
from Rocket to MiniRocket. In Section 4, we present experimental
results for MiniRocket in terms of accuracy and scalability, as well
as a sensitivity analysis in relation to key parameter choices.


**2** **RELATED WORK**

**2.1** **Current State of the Art**


Recent advances in accuracy have largely superseded the most accurate methods originally identified in [ 3 ]. According to [ 2, 27, 28 ],
the most accurate current methods for time series classification are
HIVE-COTE and its variants [ 22 ], TS-CHIEF [ 36 ], InceptionTime

[ 16 ], and Rocket [ 8 ]. However, while accuracy has improved, with
some exceptions computational complexity and a lack of scalability
remain persistent problems.
TS-CHIEF builds on Proximity Forest, an ensemble of decision
trees using distance measures as splitting criteria [ 25 ]. In addition
to distance measures, TS-CHIEF uses interval-based and spectralbased splitting criteria [36].
InceptionTime is an ensemble of convolutional neural networks
based on the Inception architecture, and is the most accurate convolutional neural network model for time series classification [ 16 ].
The Temporal Dictionary Ensemble (TDE) is a recent dictionary
method based on the frequency of occurrence of patterns in time
series [ 28 ]. TDE combines aspects of earlier dictionary methods
including cBOSS [29], a more scalable variant of BOSS [34].
Catch22 is a transform based on 22 predefined time series features, used in combination with a decision tree or random forest

[ 24 ]. On its own, catch22 is fast, but highly inaccurate: see [ 8, 27 ].



The Canonical Interval Forest (CIF) is a recent method which adapts
the Time Series Forest (TSF) to use catch22 features [ 27 ]. CIF is
significantly more accurate than either catch22 or TSF.
HIVE-COTE is an ensemble of other methods including BOSS
and TSF. Two recent variants of HIVE-COTE, namely HIVECOTE/TDE (using TDE in place of BOSS) and HIVE-COTE/CIF
(using CIF in place of TSF) have been shown to be significantly
more accurate than HIVE-COTE, or any other existing method for
time series classification [ 27, 28 ]. These variants are, in turn, based
on an updated â€˜baseâ€™ version of HIVE-COTE [2].
While state of the art in terms of accuracy, with the exception of
cBOSS these methods are limited by high computational complexity,
requiring days or even weeks to train on the datasets in the UCR
archive. While more scalable, cBOSS is significantly less accurate
than most of the other methods.


**2.2** **Rocket**


Rocket achieves state-of-the-art accuracy, matching the most accurate methods for time series classification (with the exception of
the most recent variants of HIVE-COTE), but is considerably faster
and more scalable than other methods of comparable accuracy [ 8 ].
Rocket transforms input time series using random convolutional kernels, and uses the transformed features to train a linear
classifier. Each input time series is convolved with 10 _,_ 000 random
convolutional kernels. Rocket applies global max pooling and PPV
(for â€˜proportion of positive valuesâ€™) pooling to the resulting convolution output to produce two features per kernel per input time
series, for a total of 20 _,_ 000 features per input time series. The transformed features are then used to train a linear classifier: a ridge
regression classifier, or logistic regression trained using stochastic
gradient descent (for larger datasets).
The kernels are random in terms of their length, weights, bias,
dilation, and padding: see Section 3.1. The two most important
aspects of Rocket in terms of achieving state-of-the-art accuracy
are the use of dilation, sampled on an exponential scale, and the use
of PPV. Rocket forms the basis for MiniRocket. The differences
between Rocket and MiniRocket are detailed in Section 3.


**2.3** **Other Methods**


The use of a small, fixed set of kernels differentiates MiniRocket
from both Rocket, which uses random kernels, and convolutional
neural networks such as InceptionTime, which use learned kernels.
It also differentiates MiniRocket from other methods with at least
superficial similarities to Rocket, such as random shapelet methods
as in [ 18 ], and other random methods such as those based on [ 32 ].
In using kernels with weights constrained to two values (see Section 3.1.2), there are obvious similarities with binary and quantised
convolutional neural networks [ 14, 33 ]. MiniRocket makes use of
at least two advantages of binary/quantised kernels, namely, the
ability to perform the convolution operation via addition, as well
as efficiencies arising from the relatively small number of possible
binary kernels of a given size, e.g., [ 14, 17, 33 ]. However, while the
kernels used in MiniRocket are binary in the sense of having only
two values, these values are _not_ 0 and 1 (or âˆ’ 1 and 1). In fact, the
actual values of the weights are not important: see Section 3.1.2.


MiniRocket does not use bitwise operations, and the input and
convolution output are used at full precision.
The optimisations used in MiniRocket are similar in motivation
to several optimisations developed for convolutional neural networks, i.e., broadly speaking, to reduce the number of operations
(especially multiplications) required to perform the convolution
operation, e.g., [ 6, 21, 23, 26 ]. In precomputing the product of the
kernel weights and the input, and using those precomputed values
to construct the convolution output (see Sections 3.2.3 and 3.2.4),
the optimisations used in MiniRocket bear some resemblance to
highly simplified versions of shift-based methods [ 37 ], where conventional convolutional kernels are replaced by a combination of
1 Ã— 1 convolutions and spatial shifts in the input, and lookup-based
methods [ 1 ], where the convolution operation is performed via
linear combinations of the precomputed convolution output for a
small â€˜dictionaryâ€™ of kernels.
However, the optimisations used in MiniRocket are much simpler than these methods. MiniRocket uses a fixed set of kernels,
and uses the convolution output for these kernels directly, rather
than through a learned linear combination, c.f., e.g., [ 1, 17 ]. The
optimisations arise as a natural result of using this fixed set of
kernels, rather than being general-purpose optimisations.
Several things further distinguish MiniRocket (and Rocket)
from most approaches involving convolutional neural networks.
The features produced by the transform are all independent of each
other (there is no hidden layer). Neither the convolution output
nor the pooled features are transformed through, e.g., a sigmoid
function or rectified linear unit (ReLU). As such, the classifier learns
a direct linear function of the features produced by the transform.
MiniRocket is also distinguished by its use of dilation (similar to
using many different dilations in a single convolutional layer, with
dilations taking any integer value not just powers of two), and PPV.


**3** **METHOD**


MiniRocket involves making certain key changes in order to remove almost all randomness from Rocket (Section 3.1), and exploiting these changes in order to dramatically speed up the transform (Section 3.2). In tuning kernel length, weights, bias, etc., we
have restricted ourselves to the same 40 â€˜developmentâ€™ datasets as
used in [ 8 ], with the same aim of avoiding overfitting the entire
UCR archive. (Note, however, that it is not necessarily the aim of
MiniRocket to maximise accuracy _per se_, but rather to balance
accuracy with parameter choices which remove randomness and
are conducive to optimising the transform.) The procedures for
setting the parameter values and performing the transform are set
out in fit and transform in Appendix B.
As for Rocket, we implement MiniRocket in Python, compiled
via Numba [ 20 ]. We use a ridge regression classifier from scikitlearn [ 31 ], and logistic regression implemented using PyTorch [ 30 ].
[Our code is available at: https://github.com/angus924/minirocket.](https://github.com/angus924/minirocket)


**3.1** **Removing Randomness**


Rocket uses kernels with lengths selected randomly from { 7 _,_ 9 _,_ 11 },
weights drawn from N ( 0 _,_ 1 ), bias terms drawn from U(âˆ’ 1 _,_ 1 ), random dilations, and random paddings. Two features, PPV and max,
are computed per kernel, for a total of 20 _,_ 000 features. MiniRocket



**Table 1: Summary of changes from Rocket to MiniRocket.**


Rocket MiniRocket


length {7 _,_ 9 _,_ 11} 9
weights N (0 _,_ 1) {âˆ’1 _,_ 2}
bias U(âˆ’1 _,_ 1) from convolution output
dilation random fixed (rel. to input length)
padding random fixed
features PPV + max PPV

num. features 20K 10K


is characterised by a number of key changes to the kernels in terms
of length, weights, bias, dilation, and padding, as well as resulting
changes to the features, as summarised in Table 1.


_3.1.1_ _Length._ MiniRocket uses kernels of length 9, with weights
restricted to two values, building on the observation in [ 8 ] that
weights drawn from {âˆ’ 1 _,_ 0 _,_ 1 } produce similar accuracy to weights
drawn from N (0 _,_ 1).
In order to maximise computational efficiency, the set of kernels
should be as small as possible: see Section 3.2.2. The set of possible
two-valued kernels grows exponentially with length. There are
2 [3] = 8 possible kernels of length 3, but 2 [15] = 32 _,_ 768 possible
kernels of length 15. With more than two values, the set of possible
kernels grows even faster with length. For example, there are 3 [15] â‰ˆ
14 million possible three-valued kernels of length 15.
There are 2 [9] = 512 possible two-valued kernels of length 9.
MiniRocket uses a subset of 84 of these kernels, a subset which
balances accuracy with the computational advantages of using a
small number of kernels: see Section 4.3.1. (A length of 9 is also
consistent with the average length used in Rocket.)


_3.1.2_ _Weights._ Kernels with weights restricted to two values, _ğ›¼_ and
_ğ›½_, can be characterised in terms of the number of weights with the
value _ğ›½_ (or, equivalently, the number of weights with the value _ğ›¼_ ).
In this sense, the full set of two-valued kernels of length 9 includes
the subset of kernels with 1 value of _ğ›½_ (e.g., [ _ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›½_ ] ),
the subset of kernels with 2 values of _ğ›½_ (e.g., [ _ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›½, ğ›½_ ] ),
and so on. MiniRocket uses the subset kernels with 3 values of _ğ›½_ :


[ _ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›½, ğ›½, ğ›½_ ]


[ _ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›½, ğ›¼, ğ›½, ğ›½_ ]


[ _ğ›¼, ğ›¼, ğ›¼, ğ›¼, ğ›½, ğ›¼, ğ›¼, ğ›½, ğ›½_ ]


_..._


For MiniRocket, we set _ğ›¼_ = âˆ’ 1 and _ğ›½_ = 2. However, the choice
of _ğ›¼_ and _ğ›½_ is arbitrary, in the sense that the scale of these values
is unimportant. For an input time series, _ğ‘‹_, kernel, _ğ‘Š_, and bias,
_ğ‘_, PPV is given by PPV( _ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_ ) = ~~_ğ‘›_~~ [1] ï¿½[ _ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_ _>_ 0 ] or,

equivalently, PPV( _ğ‘‹_ âˆ— _ğ‘Š_ ) = ~~_ğ‘›_~~ [1] ï¿½[ _ğ‘‹_ âˆ— _ğ‘Š_ _> ğ‘_ ], where â€˜ âˆ— â€™ denotes

convolution, and [ _ğ‘‹_ âˆˆ _ğ‘_ ] denotes the indicator function. As such,
computing PPV is essentially equivalent to computing the empirical cumulative distribution function. Accordingly, the scale of the
weights is unimportant, because bias values are drawn from the
convolution output, _ğ‘‹_ âˆ— _ğ‘Š_ (see Section 3.1.3), and so by definition
match the scale of the weights and the scale of the input. (Hence,
in contrast to Rocket, it is not necessary to normalise the input.)


It is only important that the sum of the weights should be zero or,
equivalently, that _ğ›½_ = âˆ’ 2 _ğ›¼_ . Otherwise, the values of _ğ›¼_ and _ğ›½_ are not
important. This constraintâ€”that the weights sum to zeroâ€”ensures
that the kernels are only sensitive to the relative magnitude of the
values in the input, i.e., that the convolution output is invariant to
the addition or subtraction of any constant value to the input, i.e.,
_ğ‘‹_ âˆ— _ğ‘Š_ = ( _ğ‘‹_ Â± _ğ‘_ ) âˆ— _ğ‘Š_ .
As PPV is bounded between 0 and 1, in computing PPV for
a given kernel, _ğ‘Š_, we get an equivalent feature for the inverted
kernel, âˆ’ _ğ‘Š_, â€˜for freeâ€™: see Section 3.2.1. Accordingly, there is no
need to use both the set of kernels with weights _ğ›¼_ = âˆ’ 1 and _ğ›½_ = 2,
and the corresponding inverted set of kernels with weights _ğ›¼_ = 1
and _ğ›½_ = âˆ’2, as we get these inverted kernels â€˜for freeâ€™.
The set of 84 kernels of length 9 with three weights with the
value _ğ›½_ = 2, and six weights with the value _ğ›¼_ = âˆ’ 1, has the desirable
properties of being a relatively small, fixed set of kernelsâ€”conducive
to the optimisations pursued in Section 3.2â€”and producing high
classification accuracy. However, we stress that there is not necessarily anything â€˜specialâ€™ about this set of kernels. Other subsets of
kernels of length 9, and kernels of other lengths, produce similar
accuracy: see Section 4.3.1. This is in addition to the observations
in [ 8 ], i.e., that kernels (of various lengths) with weights drawn
from N (0 _,_ 1), or from {âˆ’1 _,_ 0 _,_ 1}, are also effective.


_3.1.3_ _Bias._ Bias values are drawn from the convolution output, and
are used to compute PPV as set out above in Section 3.1.2. By default,
for a given kernel/dilation combination, bias values are drawn from
the quantiles of the convolution output for a single, randomlyselected training example. For a given kernel, _ğ‘Š_, and dilation, _ğ‘‘_, we
compute the convolution output for a randomly-selected training
example, _ğ‘‹_, i.e., _ğ‘Š_ _ğ‘‘_ âˆ— _ğ‘‹_ . We take, e.g., the [ 0 _._ 25 _,_ 0 _._ 5 _,_ 0 _._ 75 ] quantiles
from _ğ‘Š_ _ğ‘‘_ âˆ— _ğ‘‹_ as bias values, to be used in computing PPV. We
use a low-discrepancy sequence to assign quantiles to different
kernel/dilation combinations [35].
The selection of training examples for the purpose of sampling
bias values is the only stochastic element of MiniRocket. Further,
while the choice of training example is random, in drawing bias values from the convolution output, we are selecting values produced
by an otherwise entirely deterministic procedure. This is why we
characterise MiniRocket as â€˜minimally randomâ€™.
For the deterministic variant of MiniRocket, bias values are
drawn from the convolution output for the entire training set, rather
than a single, randomly-selected training example. This is the only
substantive difference between the default and deterministic variants, and the difference in accuracy between the two variants is
negligible: see Section 4.1.
The advantage of using the entire training set is an entirely
deterministic transform, for applications where this is desirable.
However, this comes at additional computational cost, which is
unlikely to be practical for larger datasets. Crucially, however, it
demonstrates that the accuracy of Rocket is achievable using an entirely deterministic transform. In practice, using a single, randomlyselected training example has little impact in terms of accuracy.
A variant of Rocket using the same method for sampling bias
values as MiniRocket is slightly more accurate than default Rocket
but, overall, the difference is relatively minor: see Section 4.1.



_3.1.4_ _Dilation._ Dilation is used to â€˜spreadâ€™ a kernel over the input.
For dilation, _ğ‘‘_, a given kernel is convolved with every _ğ‘‘_ [th] element
of the input [ 8, 38 ]. Each kernel is assigned the same fixed set
of dilations, adjusted to the length of the input time series. We
specify dilations in the range _ğ·_ = {âŒŠ 2 [0] âŒ‹ _, ...,_ âŒŠ 2 [max] âŒ‹}, where the
exponents are uniformly spaced between 0 and max = log 2 ( _ğ‘™_ input âˆ’
1 )/( _ğ‘™_ kernel âˆ’ 1 ), where _ğ‘™_ input is input length and _ğ‘™_ kernel is kernel
length (i.e., 9), such that the maximum effective length of a kernel,
including dilation, is the length of the input time series. The count
of each unique integer dilation value in _ğ·_ determines the number of
features to be computed per dilation (scaled according to the total
number of features), ensuring that, as in Rocket, exponentially
more features are computed for smaller dilations.
As time series length increases, the number of possible dilation
values increases. This means that, for a fixed number of features,
the number of features computed per dilation decreases (unless
constrained in some way), making the transform less efficient: see
Section 3.2.2. Hence, by default, we limit the maximum number of
dilations per kernel to 32. While technically an additional hyperparameter, this has little effect on accuracy (see Section 4.3.5), and is
intended to be kept at its default value.


_3.1.5_ _Padding._ Padding is alternated for each kernel/dilation combination such that, overall, half the kernel/dilation combinations
use padding, and half do not. As for Rocket, MiniRocket uses
standard zero padding. In effect, zeros are added to the start and
end of each input time series such that the convolution operation
begins with the â€˜middleâ€™ element of the kernel centered on the first
element of the time series, and ends with the â€˜middleâ€™ element of
the kernel centered on the last element of the time series [13].


_3.1.6_ _Features._ Given the other changes, there is no longer any
benefit in terms of accuracy in using global max pooling in addition
to PPV: see Section 4.3.3. Accordingly, MiniRocket â€˜dropsâ€™ global
max pooling and uses only PPV.
We do not replace global max pooling with additional PPV features. As for Rocket, the number of features represents a tradeoff
between accuracy and computational expense. MiniRocket with
10 _,_ 000 features already matches Rocket in terms of accuracy, and
there is little or no benefit in terms of accuracy to increasing the
number of features beyond 10 _,_ 000: see Section 4.3.4.
Accordingly, by default, MiniRocket uses 10 _,_ 000 features (or,
more precisely, the nearest multiple of 84â€”the number of kernelsâ€”
less than 10 _,_ 000, i.e., 9 _,_ 996). While technically a hyperparameter,
this is intended to be kept at its default value.


**3.2** **Optimising the Transform**

MiniRocket takes advantage of the properties of the small, fixed
set of two-valued kernels, and of PPV, to significantly speed up the
transform through four key optimisations:


(1) computing PPV for _ğ‘Š_ and âˆ’ _ğ‘Š_ at the same time;
(2) reusing the convolution output to compute multiple features;
(3) avoiding multiplications in the convolution operation; and
(4) for each dilation, computing all kernels (almost) â€˜at onceâ€™.


_3.2.1_ _Computing PPV for_ _ğ‘Š_ _and_ âˆ’ _ğ‘Š_ _at the Same Time._ For _ğ¶_ =
_ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_, PPV is given by PPV( _ğ¶_ ) = ~~_ğ‘›_~~ [1] ï¿½[ _ğ‘_ _>_ 0 ] _._ PPV is bounded

between 0 and 1. By definition, the proportion of negative values (or


1.5


1.0


0.5


0.0


âˆ’0.5


âˆ’1.0


âˆ’1.5







represent zero padding), e.g.:



ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°



0 0 0 0 _ğ‘¤_ 0 _ğ‘¥_ 0   - Â· Â·

0 0 0 _ğ‘¤_ 1 _ğ‘¥_ 0 _ğ‘¤_ 1 _ğ‘¥_ 1   - Â· Â·

0 0 _ğ‘¤_ 2 _ğ‘¥_ 0 _ğ‘¤_ 2 _ğ‘¥_ 1 _ğ‘¤_ 2 _ğ‘¥_ 2   - Â· Â·

_..._ _..._ _..._ _..._ _..._ _..._

ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£° _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 4 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 5 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 6 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 7 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 8 - Â· Â·





Ë†
_ğ‘ª_ =





0 20 40 60 80 100



0 20 40 60 80 100



0 0 0 0 _ğ‘¤_ 0 _ğ‘¥_ 0     - Â· Â·

0 0 0 _ğ‘¤_ 1 _ğ‘¥_ 0 _ğ‘¤_ 1 _ğ‘¥_ 1     - Â· Â·

_ğ‘ª_ Ë† = 0 0 _ğ‘¤_ 2 _ğ‘¥_ 0 _ğ‘¤_ 2 _ğ‘¥_ 1 _ğ‘¤_ 2 _ğ‘¥_ 2 - Â· Â·


_..._ _..._ _..._ _..._ _..._ _..._

ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£° _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 4 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 5 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 6 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 7 _ğ‘¤_ _ğ‘š_ âˆ’1 _ğ‘¥_ 8                                        - Â· Â·ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»


The result of the convolution operation is given by the column
sums of _ğ‘ª_ [Ë†], i.e., _ğ¶_ = _ğ‘‹_ âˆ— _ğ‘Š_ = 1 [âŠ¤] _ğ‘ª_ [Ë†], where 1 is a vector, [ 1 _,_ 1 _, ...,_ 1 ] [âŠ¤],
of length _ğ‘›_ .
Where the weights of the kernels are restricted to two values, _ğ›¼_
and _ğ›½_, we can â€˜factor outâ€™ the multiplications by precomputing _ğ´_ =
_ğ›¼ğ‘‹_ and _ğµ_ = _ğ›½ğ‘‹_ and then, for a given kernel, e.g., _ğ‘Š_ = [ _ğ›¼, ğ›½, ğ›¼, ..., ğ›¼_ ],
completing the convolution operation by summation using _ğ´_ =

[ _ğ‘_ 0 _,ğ‘_ 1 _, ...,ğ‘_ _ğ‘›_ âˆ’1 ] and _ğµ_ = [ _ğ‘_ 0 _,ğ‘_ 1 _, ...,ğ‘_ _ğ‘›_ âˆ’1 ]:



**Figure 3: Illustration of** PPV( _ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_ ) = 1 âˆ’ PPV( _ğ‘_ âˆ’( _ğ‘‹_ âˆ— _ğ‘Š_ )) **.**


PNV) is the complement of PPV, i.e., 1 âˆ’ PPV( _ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_ ) = PNV( _ğ‘‹_ âˆ—
_ğ‘Š_ âˆ’ _ğ‘_ ) _._ That is, by computing PPV, we also implicitly compute
PNV and vice versa. In this sense, PPV and PNV are equivalent.
Further, the convolution operation is associative, such that _ğ‘‹_ âˆ—
âˆ’ _ğ‘Š_ = âˆ’( _ğ‘‹_ âˆ— _ğ‘Š_ ) . Accordingly, by computing PPV for a given
kernel, _ğ‘Š_, we unavoidably also compute an equivalent feature (i.e.,
PNV) for âˆ’ _ğ‘Š_, that is, PPV( _ğ‘‹_ âˆ— _ğ‘Š_ âˆ’ _ğ‘_ ) = 1 âˆ’ PPV( _ğ‘_ âˆ’( _ğ‘‹_ âˆ— _ğ‘Š_ )) _._
This relationship is illustrated in Figure 3. This means that, for the
purposes of PPV, it is unnecessary to compute both _ğ‘‹_ âˆ— _ğ‘Š_ and
_ğ‘‹_ âˆ—âˆ’ _ğ‘Š_ . In fact, it would be redundant to do so.
This means that, in practice, for a given set of kernels where
each kernel, _ğ‘Š_, is matched by a corresponding inverted kernel, âˆ’ _ğ‘Š_,
we only need to perform the convolution operation for _ğ‘Š_, i.e., for
half of the kernels. We get âˆ’ _ğ‘Š_ â€˜for freeâ€™. Accordingly, as set out in
Section 3.1.2, MiniRocket only uses a set of kernels with weights
_ğ›¼_ = âˆ’ 1 and _ğ›½_ = 2, as it is unnecessary to also use the corresponding
set of inverted kernels with weights _ğ›¼_ = 1 and _ğ›½_ = âˆ’2.


_3.2.2_ _Reusing the Convolution Output._ For MiniRocket, the same
kernel/dilation combination is used to compute multiple features,
at least for smaller dilations (exponentially fewer features are computed for larger dilations: see Section 3.1.4).
For a given kernel, _ğ‘Š_, and dilation, _ğ‘‘_, we compute _ğ¶_ = _ğ‘‹_ âˆ— _ğ‘Š_ _ğ‘‘_
and then reuse the convolution output, _ğ¶_, to compute multiple
features, i.e., for multiple different bias values. This has the effect
that multiple features are computed with the computational cost
of a single convolution operation, plus the much lower cost of
computing PPV for each bias value.


_3.2.3_ _Avoiding Multiplications._ Restricting the kernel weights to
two values allows us to, in effect, â€˜factor outâ€™ the multiplications
from the convolution operation, and to perform the convolution
operation using only addition.
For input time series _ğ‘‹_ = [ _ğ‘¥_ 0 _,ğ‘¥_ 1 _, ...,ğ‘¥_ _ğ‘›_ âˆ’1 ], and kernel _ğ‘Š_ =

[ _ğ‘¤_ 0 _,ğ‘¤_ 1 _, ...,ğ‘¤_ _ğ‘š_ âˆ’1 ], with dilation, _ğ‘‘_, the convolution operation can
be formulated as:



ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»



Ë†
_ğ‘ª_ =



0 0 0 0 _ğ‘_ 0  - Â· Â· _ğ‘_ _ğ‘›_ âˆ’5
0 0 0 _ğ‘_ 0 _ğ‘_ 1  - Â· Â· _ğ‘_ _ğ‘›_ âˆ’4
0 0 _ğ‘_ 0 _ğ‘_ 1 _ğ‘_ 2  - Â· Â· _ğ‘_ _ğ‘›_ âˆ’3

_..._ _..._ _..._ _..._ _..._ _..._ _..._

ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£° _ğ‘_ 4 _ğ‘_ 5 _ğ‘_ 6 _ğ‘_ 7 _ğ‘_ 8    - Â· Â· 0



In other words, it is only necessary to compute _ğ›¼ğ‘‹_ and _ğ›½ğ‘‹_ once
for each input time series, and then reuse the results to complete
the convolution operation for each kernel by addition.


_3.2.4_ _Computing All the Kernels (Almost) â€˜At Onceâ€™._ We can take
further advantage of using only two values for the kernel weights in
order to perform most of the computation required for all 84 kernels
â€˜at onceâ€™ for each dilation value. More precisely, as MiniRocket
uses kernels with six weights of one value, and three weights of
another value, we can perform [6] ~~9~~ [=] [2] ~~3~~ [of the computation for all 84]

kernels â€˜at onceâ€™ for a given dilation.
This is possible by treating all kernel weights as _ğ›¼_ = âˆ’ 1, precomputing convolution output, _ğ¶_ _ğ›¼_, and later adjusting _ğ¶_ _ğ›¼_ for each
kernel. Per Section 3.2.3, _ğ¶_ _ğ›¼_ can be thought of as the column sums
of a matrix with 9 rows, where each row corresponds to _ğ›¼ğ‘‹_ = âˆ’ _ğ‘‹_,
aligned according to dilation. For example, for a dilation of 1:



ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»



Ë†
_ğ‘ª_ _ğ›¼_ =



0 0 0 0 âˆ’ _ğ‘¥_ 0  - Â· Â· âˆ’ _ğ‘¥_ _ğ‘›_ âˆ’5

0 0 0 âˆ’ _ğ‘¥_ 0 âˆ’ _ğ‘¥_ 1  - Â· Â· âˆ’ _ğ‘¥_ _ğ‘›_ âˆ’4

0 0 âˆ’ _ğ‘¥_ 0 âˆ’ _ğ‘¥_ 1 âˆ’ _ğ‘¥_ 2  - Â· Â· âˆ’ _ğ‘¥_ _ğ‘›_ âˆ’3

_..._ _..._ _..._ _..._ _..._ _..._ _..._

ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°âˆ’ _ğ‘¥_ 4 âˆ’ _ğ‘¥_ 5 âˆ’ _ğ‘¥_ 6 âˆ’ _ğ‘¥_ 7 âˆ’ _ğ‘¥_ 8  - Â· Â· 0



_ğ‘‹_ âˆ— _ğ‘Š_ _ğ‘‘_ =



_ğ‘š_ âˆ’1
âˆ‘ï¸



_ğ‘¥_ _ğ‘–_ âˆ’( âŒŠ _[ğ‘š]_ 2
_ğ‘—_ =0



2 [âŒ‹Â·] _[ğ‘‘]_ [)+(] _[ğ‘—]_ [Â·] _[ğ‘‘]_ [)] [ Â·] _[ ğ‘¤]_ _[ğ‘—]_ _[,]_ [ âˆ€] _[ğ‘–]_ [âˆˆ{][0] _[,]_ [ 1] _[, ...,ğ‘›]_ [âˆ’] [1][}] _[.]_



Equivalently, the convolution operation can be thought of as the
column sums of a matrix, _ğ‘ª_ [Ë†], where each row corresponds to the
input time series multiplied by the appropriate kernel weight, and
the alignment of the rows corresponds to dilation (values of 0 in _ğ‘ª_ [Ë†]



For MiniRocket, the kernel weights are _ğ›¼_ = âˆ’ 1 and _ğ›½_ = 2. Let
_ğ›¾_ = 3, noting that 2 = âˆ’ 1 + 3. As for _ğ‘ª_ [Ë†] _ğ›¼_, we then form _ğ‘ª_ [Ë†] _ğ›¾_, where
each row corresponds to _ğ›¾ğ‘‹_ = 3 _ğ‘‹_, aligned according to dilation.
For each kernel, _ğ¶_ _ğ›¾_ is equivalent to the column sums of those rows
in _ğ‘ª_ [Ë†] _ğ›¾_ corresponding to the position of the _ğ›½_ weights in the given
kernel. For example, for kernel _ğ‘Š_ = [ _ğ›½, ğ›¼, ğ›½, ğ›¼, ğ›½, ğ›¼, ğ›¼, ğ›¼, ğ›¼_ ]:


Ë† 0 0 0 0 3 _ğ‘¥_ 0     - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’5
_ğ‘ª_ _ğ›¾_ [(] _[ğ‘Š]_ [)] = 0 0 3 _ğ‘¥_ 0 3 _ğ‘¥_ 1 3 _ğ‘¥_ 2   - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’3
ï£®ï£¯ï£¯ï£¯ï£¯ï£°3 _ğ‘¥_ 0 3 _ğ‘¥_ 1 3 _ğ‘¥_ 2 3 _ğ‘¥_ 3 3 _ğ‘¥_ 4                           - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’1 ï£¹ï£ºï£ºï£ºï£ºï£»


The final convolution output for a given kernel is then given by
_ğ¶_ = _ğ¶_ _ğ›¼_ + _ğ¶_ _ğ›¾_ . In other words, we can reuse _ğ¶_ _ğ›¼_, computed once for a
given dilation, to compute the convolution output for all 84 kernels



Ë†
_ğ‘ª_ [(] _[ğ‘Š]_ [)] =
_ğ›¾_
ï£®ï£¯ï£¯ï£¯ï£¯ï£°



0 0 0 0 3 _ğ‘¥_ 0 - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’5

0 0 3 _ğ‘¥_ 0 3 _ğ‘¥_ 1 3 _ğ‘¥_ 2 - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’3

3 _ğ‘¥_ 0 3 _ğ‘¥_ 1 3 _ğ‘¥_ 2 3 _ğ‘¥_ 3 3 _ğ‘¥_ 4 - Â· Â· 3 _ğ‘¥_ _ğ‘›_ âˆ’1


for that dilation. For each kernel, computing _ğ¶_ only involves adding
_ğ¶_ _ğ›¾_ to _ğ¶_ _ğ›¼_ . In performing the convolution operation in this way, we
only have to compute _ğ¶_ _ğ›¾_ for each kernel, i.e., [1] ~~3~~ [of the computation]

otherwise required.


**3.3** **Classifiers**


Like Rocket, MiniRocket is a transform, producing features which
are then used to train a linear classifier. We use the same classifiers
as Rocket to learn the mapping from the features to the classes, i.e.,
a ridge regression classifier or, for larger datasets, logistic regression
trained using Adam [ 19 ]. As for Rocket, we suggest switching from
the ridge regression classifier to logistic regression when there are
more training examples than features, i.e., when there are more
than approximately 10 _,_ 000 training examples.


**3.4** **Complexity**


Fundamentally, the scalability of MiniRocket remains the same
as for Rocket: linear in the number of kernels/features ( _ğ‘˜_ ), the
number of examples ( _ğ‘›_ ), and time series length ( _ğ‘™_ input ) or, formally,
_ğ‘‚_ ( _ğ‘˜_ - _ğ‘›_ - _ğ‘™_ input ) . While MiniRocket uses a smaller number of kernel/dilation combinations, and computes multiple features for each
kernel/dilation combination, complexity is still proportional to the
number of kernels/features. Similarly, while MiniRocket â€˜factors
outâ€™ multiplications from the convolution operation, the number
of addition operations is still proportional to the number of kernels and time series length, and while MiniRocket performs the
majority of the computation required for all 84 kernels â€˜at onceâ€™,
the remaining computation is still proportional to the number of
kernels/features. However, within this broad class of complexity,
the various optimisations pursued in Section 3.2 make MiniRocket
significantly faster in practice.


**3.5** **Memory**


Compared to Rocket (which does not store any intermediate values), MiniRocket temporarily stores up to 13 additional vectors,
namely, _ğ´_ = âˆ’ _ğ‘‹_, _ğº_ = _ğ›¾ğ‘‹_ = 3 _ğ‘‹_ (plus 9 variants of _ğº_ pre-aligned
for the given dilation), _ğ¶_ _ğ›¼_, and _ğ¶_ : see Sections 3.2.3 and 3.2.4. This
is equivalent to storing 13 additional copies of a single input time
series (approx. 1 _,_ 000 _,_ 000 Ã— 4 Ã— 13 = 52 MB for time series of length
1 million), which should be negligible in almost all cases.
When transforming the training set, the deterministic variant
stores the convolution output for a given kernel/dilation combination for the entire training set, which is equivalent to storing one
additional copy of the entire training set. This is impractical for
larger datasets, which is why it is avoided by default.


**4** **EXPERIMENTS**


We evaluate MiniRocket on the datasets in the UCR archive (Section 4.1), showing that, on average, MiniRocket is marginally more
accurate than Rocket, and not significantly less accurate than the
most accurate current methods for time series classification. We
demonstrate the speed and scalability of MiniRocket in terms of
both training set size and time series length (Section 4.2), showing
that MiniRocket is up to 75 times faster than Rocket on larger
datasets. We also explore the effect of key parameters in relation to
kernel length, bias, output features, and dilation (Section 4.3).



1.0


0.8


0.6







0.4


0.2


0.0





0.0 0.2 0.4 0.6 0.8 1.0

Rocket


**Figure 4: Pairwise accuracy of MiniRocket versus Rocket.**


**4.1** **UCR Archive**


We evaluate MiniRocket on the datasets in the UCR archive [ 7 ]. We
compare MiniRocket against the most accurate current methods
for time series classification, namely, HIVE-COTE/TDE (representative of HIVE-COTE and its variants), TS-CHIEF, InceptionTime,
and Rocket, as well as TDE, CIF, cBOSS and Proximity Forest.
For consistency and direct comparability with the most recent
published results for other state-of-the-art methods [ 2, 27, 28 ], we
evaluate MiniRocket on 30 resamples of 109 datasets from the
archive. We use the same 30 resamples (including the default training/test split) as in [ 2, 27, 28 ]. (Full results are available in the
accompanying repository.)
Figure 1 on page 1 shows the mean rank of MiniRocket versus
the other state-of-the-art methods. Methods for which the pairwise
difference in accuracy is not statistically significant, per a Wilcoxon
signed-rank test with Holm correction (as a post hoc test to the
Friedman test), are connected with a black line [4, 9, 12].
MiniRocket is, on average, marginally more accurate than
Rocket, and somewhat less accurate than the most accurate current
methods, namely TS-CHIEF and HIVE-COTE/TDE, although the
differences in accuracy are not statistically significant. However,
as noted in Section 1, the total compute time for MiniRocket on
these datasets is a tiny fraction of the total compute time required
by the other methods (even Rocket, which is already considerably
faster than even the fastest of the other methods).


_MiniRocket versus Rocket._ Figure 4 shows the pairwise accuracy of MiniRocket versus Rocket for the same 109 datasets.
Overall, MiniRocket and Rocket achieve very similar accuracy.
MiniRocket is more accurate than Rocket on 61 datasets, and less
accurate on 45 datasets, but the differences in accuracy are mostly
small. The large difference in accuracy between MiniRocket and
Rocket on one dataset, _PigAirwayPressure_, appears to be due to
the way the bias values are sampled. We also evaluated a variant of Rocket which uses the same method of sampling bias values as MiniRocket. Overall, this variant is slightly more accurate
than default Rocket, but the difference is relatively minor, with a
win/draw/loss of 50/6/53 against MiniRocket.


0.0 0.2 0.4 0.6 0.8 1.0

MiniRocket DV


**Figure 5: Pairwise accuracy of default MiniRocket versus**
**the deterministic variant.**


**Table 2: Accuracy and total training time.**


Accuracy Training Time


Rocket MiniRocket Rocket MiniRocket


_Fruit_ 0.9491 0.9568 2h 36m 40s 2m 22s

_Insect_ 0.7796 0.7639 26m 44s 37s

_Mosquito_ 0.8271 0.8165 15h 34m 58s 12m 32s


_Deterministic variant._ Figure 5 shows the pairwise accuracy of default MiniRocket vs the deterministic variant (or MiniRocket DV )
for the same 109 datasets. Overall, the deterministic variant produces essentially the same accuracy as the default variant.


**4.2** **Scalability**


_4.2.1_ _Training Set Size._ We demonstrate the speed and scalability
of MiniRocket in terms of training set size on the three largest
datasets in the UCR archive, namely, _MosquitoSound_ (139 _,_ 780 training examples, each of length 3 _,_ 750), _InsectSound_ (25 _,_ 000 training
examples, each of length 600), and _FruitFlies_ (17 _,_ 259 training examples, each of length 5 _,_ 000). These recent additions are significantly
larger than other datasets in the archive.
For this purpose, following [ 8 ], we integrate MiniRocket (and
Rocket) with logistic regression, trained using Adam. Training details are provided in Appendix A. The experiments were performed
on the same cluster as noted in Section 1 and, again, both Rocket
and MiniRocket are restricted to a single CPU core.
Figure 6 shows training time vs training set size for MiniRocket
and Rocket. Training time includes the transform for both validation and training sets, and classifier training. Table 2 shows test
accuracy and total training time (for the full training set).
MiniRocket is slightly more accurate on one of the datasets,
and slightly less accurate on two of the datasets. This is consistent with the small differences in accuracy observed on the other
datasets in the UCR archive: see Section 4.1. However, MiniRocket
is considerably faster than Rocket: 43 times faster on _InsectSound_,
66 times faster on _FruitFlies_, and 75 times faster on _MosquitoSound_ .



The accuracy of Rocket and MiniRocket on the _InsectSound_
and _MosquitoSound_ datasets appears to be broadly comparable to
reported results for other methods for these datasets or versions
of these datasets [ 5, 10, 11, 39 ], although some deep learning approaches are significantly more accurate on _MosquitoSound_ [10].


_4.2.2_ _Time Series Length._ We demonstrate the scalability of
MiniRocket in terms of time series length on the dataset in the
UCR archive with the longest time series, _DucksAndGeese_ (50 training examples, each of length 236 _,_ 784). This recent addition has
significantly longer time series than other datasets in the archive.
Figure 6 shows training time versus time series length for both
Rocket and MiniRocket. Training time includes the transform
and classifier training. (With only 50 training examples, we use the
ridge regression classifier.)
While both Rocket and MiniRocket are linear in time series

length, MiniRocket is considerably faster for a given length. With
more training examples, we would expect the difference in training
time to be considerably larger. With only 50 training examples, the
overhead of sampling bias values (which is unrelated to training
set size) constitutes a significant proportion of the total training
time for MiniRocket.


**4.3** **Sensitivity Analysis**

We explore the effect of key parameter choices on accuracy:


  - kernel length;

  - sampling bias from the convolution output versus U(âˆ’ 1 _,_ 1 ) ;

  - using only PPV versus both PPV and global max pooling;

  - the number of features; and

  - limiting the maximum number of dilations per kernel.


We perform the analysis using the 40 â€˜developmentâ€™ datasets
(default training/test splits). Results are mean results over 10 runs.


_4.3.1_ _Kernels._ Figure 7 shows the effect of kernel length on accuracy. For kernels of length 9, a subscript refers to a particular
subset of kernels in the sense discussed in Section 3.1.2. (E.g., 9 {3}
refers to kernels with three weights of one value, and six weights
of another value.) The total number of features is kept constant (to
the nearest multiple of the number of kernels less than 10 _,_ 000: see
Section 3.1.6), such that more features are computed per kernel for
smaller sets of kernels and vice versa.

Kernels of length 9 are most accurate, but kernels of length 7
or 11 are not significantly less accurate. This is consistent with
the findings in [ 8 ] in relation to Rocket. The actual differences in
accuracy between kernels of different lengths is very small.
Crucially, however, as noted in Section 3.1.2, the 9 {3} subset is
nearly as accurate as the full set of kernels of length 9. This is a
relatively small subset of kernels, and is particularly well suited to
the optimisations pursued in Section 3.2.


_4.3.2_ _Bias._ Figure 8 shows the effect in terms of accuracy of sampling bias from the convolution output versus from U(âˆ’ 1 _,_ 1 ) as
in Rocket. MiniRocket is significantly less accurate when sampling bias from U(âˆ’ 1 _,_ 1 ) . The change to sampling bias from the
convolution output is critical to matching the accuracy of Rocket.


_4.3.3_ _Features._ Figure 9 shows the effect of using only PPV versus both PPV and global max pooling. With the other changes to


_MosquitoSound_


2 [10] 2 [12] 2 [14] 2 [16] 2 [18]


Training Set Size



10m


1m


6s


600ms



_DucksAndGeese_


2 [10] 2 [12] 2 [14] 2 [16] 2 [18]


Time Series Length



10h


1h


6m


36s


3.6s



_FruitFlies_



2 [10] 2 [12] 2 [14] 2 [16] 2 [18]


Training Set Size



_InsectSound_


2 [10] 2 [12] 2 [14] 2 [16] 2 [18]


Training Set Size



**Figure 6: Training time versus (left) training set size and (right) time series length.**



7 6 5 4 3 2 1



5 4 3 2 1



9 {1}
9 {2}

11
9 {4}



9
9 {3} (DEFAULT)
7



8
16
119



32 (DEFAULT)
64



**Figure 7: Mean rank for different kernel lengths.**


2 1


uniform conv. output (DEFAULT)


**Figure 8: Mean rank for bias sampled from the convolution**
**output versus bias sampled from** U(âˆ’1 _,_ 1) **.**


2 1


PPV + max PPV (DEFAULT)


**Figure 9: Mean rank for PPV vs PPV and global max pooling.**


7 6 5 4 3 2 1



84
420
924
4,956



49,980
9,996 (DEFAULT)
99,960



**Figure 11: Mean rank of different values for the maximum**
**number of dilations per kernel.**


the same). For 49 _,_ 980 and 99 _,_ 960 features, we have endeavoured to
avoid this limitation as much as possible by setting the maximum
number of dilations per kernel to 119 (see Section 3.1.4) and, where
necessary, sampling bias values from multiple training examples.


_4.3.5_ _Dilation._ Figure 11 shows the effect in terms of accuracy of
different values for the maximum number of dilations per kernel.
The total number of features is kept constant, such that more features are computed per dilation for a smaller number of maximum
dilations per kernel and vice versa: see Section 3.1.4. There is little
difference in accuracy between values of 16 and 119 (119 being
the largest possible number of dilations per kernel for the default
number of features, i.e., âŒŠ 10 _,_ 000 /84âŒ‹ = 119). A value of 32 balances
accuracy with the computational advantage of limiting the number
of dilations per kernel, as discussed in Section 3.1.4.


**5** **CONCLUSION**


We reformulate Rocket into a new method, MiniRocket, making
it up to 75 times faster on larger datasets. MiniRocket shows that
it is possible to achieve essentially the same accuracy as Rocket
using a mostly-deterministic and much faster procedure.
MiniRocket represents a significant advance in accuracy relative to computational cost. MiniRocket is much faster than any
other method of comparable accuracy (including Rocket), and
far more accurate than any other method of even roughly-similar
computational expense. Accordingly, we suggest that MiniRocket
should be considered and used as the default variant of Rocket.

We provide a naÃ¯ve facility for applying MiniRocket to multivariate time series (available through the accompanying repository).
In future work, we propose to investigate more sophisticated approaches to multivariate time series, to explore the integration of
MiniRocket with nonlinear classifiers, and the use of MiniRocket
beyond time series data.



**Figure 10: Mean rank for different numbers of features.**


MiniRocketâ€”in particular, with the change to sampling bias from
the convolution outputâ€”there is no advantage to using global max
pooling in addition to PPV. In fact, using global max pooling in
addition to PPV is less accurate than just using PPV, although the
difference is not statistically significant.


_4.3.4_ _Number of Features._ Figure 10 shows the effect of different
numbers of features between 84 and 99 _,_ 960 (the nearest multiple of
84 less than 100, 500, 1 _,_ 000, ...). Increasing the number of features
noticeably increases accuracy up to approximately 10 _,_ 000 features.
There is little or no benefit to increasing the number of features
beyond 10 _,_ 000, at least for shorter time series, because there is little
benefit in computing PPV for many more than _ğ‘™_ input bias values
for time series of length _ğ‘™_ input (more and more features will be


**ACKNOWLEDGMENTS**


This material is based on work supported by an Australian Government Research Training Program Scholarship, and the Australian
Research Council under award DP190100017. The authors would

like to thank Professor Eamonn Keogh and all the people who have
contributed to the UCR time series classification archive. Figures
showing mean ranks were produced using code from [15].


**REFERENCES**


[1] Hessam Bagherinezhad, Mohammad Rastegari, and Ali Farhadi. 2017. LCNN:
Lookup-based Convolutional Neural Network. In _2017 IEEE Conference on Com-_
_puter Vision and Pattern Recognition_ . 860â€“869.

[2] Anthony Bagnall, Michael Flynn, James Large, Jason Lines, and Matthew Middlehurst. 2020. On the Usage and Performance of the Hierarchical Vote Collective
of Transformation-Based Ensembles Version 1.0 (HIVE-COTE v1.0). In _ECML_
_PKDD Workshop on Advanced Analytics and Learning on Temporal Data_ .

[3] Anthony Bagnall, Jason Lines, Aaron Bostrom, James Large, and Eamonn Keogh.
2017. The great time series classification bake off: a review and experimental
evaluation of recent algorithmic advances. _Data Mining and Knowledge Discovery_
31, 3 (2017), 606â€“660.

[4] Alessio Benavoli, Giorgio Corani, and Francesca Mangili. 2016. Should We Really
Use Post-Hoc Tests Based on Mean-Ranks? _Journal of Machine Learning Research_
17, 5 (2016), 1â€“10.

[5] Yanping Chen, Adena Why, Gustavo Batista, Agenor Mafra-Neto, and Eamonn
Keogh. 2014. Flying Insect Classification with Inexpensive Sensors. _Journal of_
_Insect Behavior_ 27, 5 (2014), 657â€“677.

[6] FranÃ§ois Chollet. 2017. Xception: Deep Learning with Depthwise Separable
Convolutions. In _2017 IEEE Conference on Computer Vision and Pattern Recognition_ .
1800â€“1807.

[7] Hoang An Dau, Anthony Bagnall, Kaveh Kamgar, Chin-Chia Michael Yeh, Yan
Zhu, Shaghayegh Gharghabi, Chotirat Ann Ratanamahatana, and Eamonn Keogh.
2019. The UCR Time Series Archive. _IEEE/CAA Journal of Automatica Sinica_ 6, 6
(2019), 1293â€“1305.

[8] Angus Dempster, FranÃ§ois Petitjean, and Geoffrey I Webb. 2020. ROCKET: Exceptionally fast and accurate time classification using random convolutional kernels.
_Data Mining and Knowledge Discovery_ 34, 5 (2020), 1454â€“1495.

[9] Janez DemÅ¡ar. 2006. Statistical Comparisons of Classifiers over Multiple Data
Sets. _Journal of Machine Learning Research_ 7 (2006), 1â€“30.

[10] Eleftherios Fanioudakis, Matthias Geismar, and Ilyas Potamitis. 2018. Mosquito
wingbeat analysis and classification using deep learning. In _European Signal_
_Processing Conference_ . 2424â€“2428.

[11] Michael Flynn and Anthony Bagnall. 2019. Classifying Flies Based on Reconstructed Audio Signals. In _Intelligent Data Engineering and Automated Learning_,
Hujun Yin, David Camacho, Peter Tino, Antonio J. TallÃ³n-Ballesteros, Ronaldo
Menezes, and Richard Allmendinger (Eds.). Springer, Cham, 249â€“258.

[12] Salvador GarcÃ­a and Francisco Herrera. 2008. An Extension on â€œStatistical Comparisons of Classifiers over Multiple Data Setsâ€ for All Pairwise Comparisons.
_Journal of Machine Learning Research_ 9 (2008), 2677â€“2694.

[13] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. _Deep Learning_ . MIT
Press, Cambridge, MA.

[14] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. 2018. Quantized Neural Networks: Training Neural Networks with Low
Precision Weights and Activations. _Journal of Machine Learning Research_ 18, 187
(2018), 1â€“30.

[15] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar,
and Pierre-Alain Muller. 2019. Deep learning for time series classification: a
review. _Data Mining and Knowledge Discovery_ 33, 4 (2019), 917â€“963.

[16] Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier,
Daniel F. Schmidt, Jonathan Weber, Geoffrey I. Webb, Lhassane Idoumghar, PierreAlain Muller, and FranÃ§ois Petitjean. 2020. InceptionTime: Finding AlexNet for
Time Series Classification. _Data Mining and Knowledge Discovery_ 34, 6 (2020),
1936â€“1962.

[17] Felix Juefei-Xu, Vishnu Naresh Boddeti, and Marios Savvides. 2017. Local Binary
Convolutional Neural Networks. In _2017 IEEE Conference on Computer Vision and_
_Pattern Recognition_ . 4284â€“4293.

[18] Isak Karlsson, Panagiotis Papapetrou, and Henrik BostrÃ¶m. 2016. Generalized
random shapelet forests. _Data Mining and Knowledge Discovery_ 30, 5 (2016),
1053â€“1085.

[19] Diederik P. Kingma and Jimmy Lei Ba. 2015. Adam: A Method for Stochastic Optimization. In _Third International Conference on Learning Representations_ .
arXiv:1412.6980.

[20] Siu Kwan Lam, Antoine Pitrou, and Stanley Seibert. 2015. Numba: A LLVM-based
Python JIT Compiler. In _Proceedings of the Second Workshop on the LLVM Compiler_
_Infrastructure in HPC_ . 1â€“6.




[21] Andrew Lavin and Scott Gray. 2016. Fast Algorithms for Convolutional Neural
Networks. In _2016 IEEE Conference on Computer Vision and Pattern Recognition_ .
4013â€“4021.

[22] Jason Lines, Sarah Taylor, and Anthony Bagnall. 2018. Time Series Classification
with HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based
Ensembles. _ACM Transactions on Knowledge Discovery from Data_ 12, 5 (2018),
52:1â€“52:35.

[23] Baoyuan Liu, Min Wang, Hassan Foroosh, Marshall Tappen, and Marianna Penksy.
2015. Sparse Convolutional Neural Networks. In _2015 IEEE Conference on Com-_
_puter Vision and Pattern Recognition_ . 806â€“814.

[24] Carl H. Lubba, Sarab S. Sethi, Philip Knaute, Simon R. Schultz, Ben D. Fulcher,
and Nick S. Jones. 2019. catch22: CAnonical Time-series CHaracteristics. _Data_
_Mining and Knowledge Discovery_ 33, 6 (2019), 1821â€“1852.

[25] Benjamin Lucas, Ahmed Shifaz, Charlotte Pelletier, Lachlan Oâ€™Neill, Nayyar Zaidi,
Bart Goethals, FranÃ§ois Petitjean, and Geoffrey I. Webb. 2019. Proximity Forest:
an effective and scalable distance-based classifier for time series. _Data Mining_
_and Knowledge Discovery_ 33, 3 (2019), 607â€“635.

[26] Sachin Mehta, Mohammad Rastegari, Anat Caspi, Linda Shapiro, and Hannaneh
Hajishirzi. 2018. ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for
Semantic Segmentation. In _European Conference on Computer Vision_, Vittorio
Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss (Eds.). Springer,
Cham, 561â€“580.

[27] Matthew Middlehurst, James Large, and Anthony Bagnall. 2020b. The Canonical
Interval Forest (CIF) Classifier for Time Series Classification. In _IEEE International_
_Conference on Data Mining_ .

[28] Matthew Middlehurst, James Large, Gavin Cawley, and Anthony Bagnall. 2020a.
The Temporal Dictionary Ensemble (TDE) Classifier for Time Series Classification.
In _ECML PKDD_ .

[29] Matthew Middlehurst, William Vickers, and Anthony Bagnall. 2019. Scalable
Dictionary Classifiers for Time Series Classification. In _Intelligent Data Engineer-_
_ing and Automated Learning_, Hujun Yin, David Camacho, Peter Tino, Antonio J.
TallÃ³n-Ballesteros, Ronaldo Menezes, and Richard Allmendinger (Eds.). Springer,
Cham, 11â€“19.

[30] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, et al .
2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In
_Advances in Neural Information Processing Systems 32_, H. Wallach, H. Larochelle,
A. Beygelzimer, F. dâ€˜AlchÃ© Buc, E. Fox, and R. Garnett (Eds.). 8024â€“8035.

[31] Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, et al . 2011. Scikit-learn:
Machine Learning in Python. _Journal of Machine Learning Research_ 12 (2011),
2825â€“2830.

[32] Ali Rahimi and Benjamin Recht. 2008. Random Features for Large-Scale Kernel
Machines. In _Advances in Neural Information Processing Systems 20_, J. C. Platt,
D. Koller, Y. Singer, and S. T. Roweis (Eds.). 1177â€“1184.

[33] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016.
XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks. In _European Conference on Computer Vision_, Bastian Leibe, Jiri Matas, Nicu
Sebe, and Max Welling (Eds.). Springer, Cham, 525â€“542.

[34] Patrick SchÃ¤fer. 2015. The BOSS is concerned with time series classification in the
presence of noise. _Data Mining and Knowledge Discovery_ 29, 6 (2015), 1505â€“1530.

[35] Colas Schretter, Zhijian He, Mathieu Gerber, Nicolas Chopin, and Harald Niederreiter. 2016. Van der Corput and Golden Ratio Sequences Along the Hilbert SpaceFilling Curve. In _Eleventh International Conference on Monte Carlo and Quasi-_
_Monte Carlo Methods in Scientific Computing_, Ronald Cools and Dirk Nuyens
(Eds.). Springer, Cham, 531â€“544.

[36] Ahmed Shifaz, Charlotte Pelletier, FranÃ§ois Petitjean, and Geoffrey I. Webb. 2020.
TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification. _Data Mining and Knowledge Discovery_ (2020).

[37] Bichen Wu, Alvin Wan, Xiangyu Yue, Peter Jin, Sicheng Zhao, Noah Golmant,
Amir Gholaminejad, Joseph Gonzalez, and Kurt Keutzer. 2018. Shift: A Zero
FLOP, Zero Parameter Alternative to Spatial Convolutions. In _2018 IEEE/CVF_
_Conference on Computer Vision and Pattern Recognition_ . 9127â€“9135.

[38] Fisher Yu and Vladlen Koltun. 2016. Multi-Scale Context Aggregation by Dilated
Convolutions. In _Fourth International Conference on Learning Representations_ .
arXiv:1511.07122.

[39] Chongsheng Zhang, Pengyou Wang, Hui Guo, Gaojuan Fan, Ke Chen, and JoniKristian KÃ¤mÃ¤rÃ¤inen. 2017. Turning wingbeat sounds into spectrum images for
acoustic insect classification. _Electronics Letters_ 53, 25 (2017), 1674â€“1676.


**A** **LOGISTIC REGRESSION TRAINING**


For each dataset, we shuffle the training set once, and train on increasingly large subsets of the shuffled training data. The transform
is performed in batches (of 2 [12] training examples), which are further
divided into minibatches for training. We use the same hyperparameters for all datasets: a validation set of 2 _,_ 048 examples, a minibatch
size of 256, an initial learning rate 10 [âˆ’][4], the learning rate is halved
if validation loss does not improve after 50 updates, and training is
stopped if validation loss does not improve after 100 updates. The
same hyperparameters can be reused for any dataset, because the
classifier â€˜always sees the same thingâ€™, i.e., blocks of transformed
features. Additionally, we cache the transformed features, in order
to avoid unnecessarily repeating the transform when training for
multiple epochs.


**B** **ALGORITHM**


**Function** transform( _ğ‘¿, ğ·, ğ‘, ğµ_ )


**input :** _ğ‘¿_ : time series
_ğ·_ : dilations

_ğ‘_ : num features per dilation
_ğµ_ : biases


**output:** _ğ‘­_ : features


**begin**

// indices of _ğ›½_ weights in kernels
_ğ‘°_ â†[[0 _,_ 1 _,_ 2] _,_ [0 _,_ 1 _,_ 3] _, . . .,_ [6 _,_ 7 _,_ 8]]


**for** _ğ‘–_ âˆˆ[0 _,_ 1 _, . . .,_ size( _ğ‘¿_ ) âˆ’ 1] **do**


_ğ‘_ â† 0


_ğ‘‹_ â† _ğ‘¿_ [ _ğ‘–_ ]

_ğ´,ğº_ â†âˆ’ _ğ‘‹,_ 3 _ğ‘‹_ // Â§3.2.3


**for** _ğ‘—_ âˆˆ[0 _,_ 1 _, . . .,_ | _ğ·_ | âˆ’ 1] **do**


_ğ‘_ Ë† 0 â† _ğ‘—_ mod 2
_ğ‘_ â† 4 Â· _ğ·_ [ _ğ‘—_ ]


precompute _ğ¶_ _ğ›¼_ _,_ _ğ‘ª_ [Ë†] _ğ›¾_ for _ğ·_ [ _ğ‘—_ ] per Â§3.2.4


**for** _ğ‘˜_ âˆˆ[0 _,_ 1 _, . . .,_ 83] **do**


_ğ‘_ â† _ğ‘_ + _ğ‘_ [ _ğ‘—_ ]


_ğ¶_ _ğ›¾_ â† _ğ‘ª_ [Ë†] _ğ›¾_ [ _ğ‘°_ [ _ğ‘˜_ ]] // Â§3.2.4
_ğ¶_ â† _ğ¶_ _ğ›¼_ + _ğ¶_ _ğ›¾_


_ğ‘_ Ë† 1 â† _ğ‘_ Ë† 0 + _ğ‘˜_ mod 2 // Â§3.1.5
**if** Ë† _ğ‘_ 1 **then** _ğ¶_ â† _ğ¶_ [ _ğ‘_ :| _ğ¶_ | âˆ’ _ğ‘_ ]


_ğ‘­_ [ _ğ‘–,ğ‘_ : _ğ‘_ ] â† PPV( _ğ¶, ğµ_ [ _ğ‘_ : _ğ‘_ ])


_ğ‘_ â† _ğ‘_


**end**

**end**

**end**

**return** _ğ‘­_
**end**



**Function** fit( _ğ‘¿,ğ‘›,ğ‘š_ )


**input :** _ğ‘¿_ : time series
_ğ‘›_ : num features

_ğ‘š_ : max dilations per kernel


**output:** _ğ·_ : dilations
_ğ‘_ : num features per dilation
_ğµ_ : biases

**begin**

max â† log 2 (length( _ğ‘¿_ ) âˆ’ 1)/8 // Â§3.1.4
_ğ·_ Ë† â†[âŒŠ2 [0] âŒ‹ _,_ âŒŠ2 [max][/] _[ğ‘š]_ âŒ‹ _,_ âŒŠ2 [2][Â·][max][/] _[ğ‘š]_ âŒ‹ _, . . .,_ âŒŠ2 _[ğ‘š]_ [Â·][max][/] _[ğ‘š]_ âŒ‹]


_ğ·_ â† unique elements in _ğ·_ [Ë†]

Ë†
_ğ‘_ â† count of each unique element in Ë† _ğ·_

_ğ‘_ â†âŒŠ _ğ‘_ [Ë†]  - _ğ‘›_ /84/ _ğ‘š_ âŒ‹ // scale to _ğ‘›_, s.t. sum( _ğ‘_ ) â‰ˆ _ğ‘›_


_ğ‘Ÿ_ â† _ğ‘›_ âˆ’ sum( _ğ‘_ ) // apportion remainder
**if** _ğ‘Ÿ_ _>_ 0 **then** _ğ‘_ [: _ğ‘Ÿ_ ] â† _ğ‘_ [: _ğ‘Ÿ_ ] + 1


_ğ‘„_ â† _ğ‘–_  - [1][+] ~~2âˆš~~ 5 mod 1 _,_ âˆ€ _ğ‘–_ âˆˆ[1 _,_ 2 _, . . .,ğ‘›_ ] // Â§3.1.3

_ğµ_ â† sample( _ğ‘¿, ğ·, ğ‘,ğ‘„_ )


**return** _ğ·, ğ‘, ğµ_
**end**


**Function** sample( _ğ‘¿, ğ·, ğ‘,ğ‘„_ )


**input :** _ğ‘¿_ : time series
_ğ·_ : dilations

_ğ‘_ : num features per dilation
_ğ‘„_ : quantiles


**output:** _ğµ_ : biases


**begin**

// indices of _ğ›½_ weights in kernels
_ğ‘°_ â†[[0 _,_ 1 _,_ 2] _,_ [0 _,_ 1 _,_ 3] _, . . .,_ [6 _,_ 7 _,_ 8]]


_ğ‘_ â† 0


**for** _ğ‘—_ âˆˆ[0 _,_ 1 _, . . .,_ | _ğ·_ | âˆ’ 1] **do**


**for** _ğ‘˜_ âˆˆ[0 _,_ 1 _, . . .,_ 83] **do**


_ğ‘_ â† _ğ‘_ + _ğ‘_ [ _ğ‘—_ ]


_ğ‘‹_ â† random( _ğ‘¿_ )

_ğ´,ğº_ â†âˆ’ _ğ‘‹,_ 3 _ğ‘‹_ // Â§3.2.3


compute _ğ¶_ _ğ›¼_ _,_ _ğ‘ª_ [Ë†] _ğ›¾_ for _ğ·_ [ _ğ‘—_ ] per Â§3.2.4
_ğ¶_ _ğ›¾_ â† _ğ‘ª_ [Ë†] _ğ›¾_ [ _ğ‘°_ [ _ğ‘˜_ ]]
_ğ¶_ â† _ğ¶_ _ğ›¼_ + _ğ¶_ _ğ›¾_


_ğµ_ [ _ğ‘_ : _ğ‘_ ] â† quantiles( _ğ¶,ğ‘„_ [ _ğ‘_ : _ğ‘_ ]) // Â§3.1.3


_ğ‘_ â† _ğ‘_


**end**

**end**

**return** _ğµ_
**end**


