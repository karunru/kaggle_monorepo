08/16/2025 04:47:18 PM INFO __main__: Starting cross-validation training
08/16/2025 04:47:18 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp023', 'name': 'exp023_human_normalization', 'description': 'Human Normalization using anthropometrics for body-size invariant IMU features', 'tags': ['human_normalization', 'anthropometrics', 'physics_features', 'squeezeformer', 'pytorch_lightning']}, 'paths': {'output_dir': '../../../outputs/exp023'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp023', 'wandb_tags': ['exp023', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp023', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/16/2025 04:47:18 PM INFO __main__: Starting training for fold 0
08/16/2025 04:47:23 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/train.py", line 250, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/train.py", line 129, in train_single_fold
    data_module.setup("fit")
    ~~~~~~~~~~~~~~~~~^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/src/utils/timer.py", line 39, in wrapper
    result = func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/dataset.py", line 1253, in setup
    self.train_dataset = IMUDataset(
                         ~~~~~~~~~~^
        train_sequence_ids,
        ^^^^^^^^^^^^^^^^^^^
    ...<7 lines>...
        handedness_flip_prob=self.config.augmentation.handedness_flip_prob,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/dataset.py", line 596, in __init__
    self._create_label_mappings()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/dataset.py", line 717, in _create_label_mappings
    for idx, gesture in enumerate(self.target_gestures):
                                  ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'IMUDataset' object has no attribute 'target_gestures'
08/16/2025 04:50:56 PM INFO __main__: Starting cross-validation training
08/16/2025 04:50:56 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp023', 'name': 'exp023_human_normalization', 'description': 'Human Normalization using anthropometrics for body-size invariant IMU features', 'tags': ['human_normalization', 'anthropometrics', 'physics_features', 'squeezeformer', 'pytorch_lightning']}, 'paths': {'output_dir': '../../../outputs/exp023'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp023', 'wandb_tags': ['exp023', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp023', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/16/2025 04:50:56 PM INFO __main__: Starting training for fold 0
08/16/2025 04:52:36 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 04:53:45 PM INFO __main__: Starting cross-validation training
08/16/2025 04:53:45 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp023', 'name': 'exp023_human_normalization', 'description': 'Human Normalization using anthropometrics for body-size invariant IMU features', 'tags': ['human_normalization', 'anthropometrics', 'physics_features', 'squeezeformer', 'pytorch_lightning']}, 'paths': {'output_dir': '../../../outputs/exp023'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 128, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp023', 'wandb_tags': ['exp023', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp023', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/16/2025 04:53:45 PM INFO __main__: Starting training for fold 0
08/16/2025 04:55:34 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 04:57:21 PM ERROR __main__: Error in fold 0
Traceback (most recent call last):
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/train.py", line 250, in train_cross_validation
    fold_result = train_single_fold(config, fold, logger, wandb_logger)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/train.py", line 173, in train_single_fold
    trainer.fit(model, data_module)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
    ~~~~~~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
    ~~~~~~~~~~~~^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 344, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        trainer,
        ^^^^^^^^
    ...<4 lines>...
        train_step_and_backward_closure,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/core/module.py", line 1328, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/amp.py", line 79, in optimizer_step
    closure_result = closure()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/model.py", line 918, in training_step
    multiclass_logits, binary_logits, nine_class_logits = self(imu, attention_mask, demographics)
                                                          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/model.py", line 868, in forward
    x = block(x, attention_mask)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/codes/exp/exp023/model.py", line 437, in forward
    attn_output, _ = self.self_attn(x, x, x, key_padding_mask=key_padding_mask)
                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 1373, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        query,
        ^^^^^^
    ...<17 lines>...
        is_causal=is_causal,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 6374, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
  File "/home/karunru/Home/Kaggle/kaggle_monorepo/projects/CMI_Detect_Behavior_with_Sensor_Data/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 2140, in softmax
    ret = input.softmax(dim)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 15.63 GiB of which 66.56 MiB is free. Process 974224 has 4.42 GiB memory in use. Process 300670 has 8.76 GiB memory in use. Including non-PyTorch memory, this process has 2.34 GiB memory in use. Of the allocated memory 2.11 GiB is allocated by PyTorch, and 35.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
08/16/2025 08:13:34 PM INFO __main__: Starting cross-validation training
08/16/2025 08:13:34 PM INFO __main__: Configuration: {'experiment': {'exp_num': 'exp023', 'name': 'exp023_human_normalization', 'description': 'Human Normalization using anthropometrics for body-size invariant IMU features', 'tags': ['human_normalization', 'anthropometrics', 'physics_features', 'squeezeformer', 'pytorch_lightning']}, 'paths': {'output_dir': '../../../outputs/exp023'}, 'data': {'root': '../../../data', 'train_path': '../../../data/train.csv', 'test_path': '../../../data/test.csv', 'demographics_train_path': '../../../data/train_demographics.csv', 'demographics_test_path': '../../../data/test_demographics.csv'}, 'demographics': {'enabled': True, 'embedding_dim': 16, 'categorical_embedding_dims': {'adult_child': 2, 'sex': 2, 'handedness': 2}, 'numerical_scaling_method': 'minmax', 'clip_outliers': True, 'age_min': 8.0, 'age_max': 60.0, 'height_min': 130.0, 'height_max': 195.0, 'shoulder_to_wrist_min': 35.0, 'shoulder_to_wrist_max': 75.0, 'elbow_to_wrist_min': 15.0, 'elbow_to_wrist_max': 50.0, 'categorical_features': ['adult_child', 'sex', 'handedness'], 'numerical_features': ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'], 'hn_enabled': False, 'hn_eps': 0.001, 'hn_radius_min_max': (0.15, 0.9), 'hn_features': ['linear_acc_mag_per_h', 'linear_acc_mag_per_rS', 'linear_acc_mag_per_rE', 'acc_over_centripetal_rS', 'acc_over_centripetal_rE', 'alpha_like_rS', 'alpha_like_rE', 'v_over_h', 'v_over_rS', 'v_over_rE']}, 'bert': {'hidden_size': None, 'num_layers': 4, 'num_heads': 8, 'intermediate_size': None}, 'model': {'name': 'cmi_squeezeformer_bert', 'input_dim': 16, 'd_model': 256, 'n_layers': 8, 'n_heads': 8, 'd_ff': 1024, 'num_classes': 18, 'kernel_size': 31, 'dropout': 0.1}, 'training': {'seed': 42, 'batch_size': 64, 'num_workers': 4, 'epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'gradient_clip_val': 0.5, 'scheduler_type': 'cosine', 'scheduler_min_lr': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'early_stopping_patience': 15, 'use_mixed_precision': True, 'accumulate_grad_batches': 1}, 'loss': {'type': 'acls', 'alpha': 0.5, 'focal_gamma': 2.0, 'focal_alpha': 1.0, 'soft_f1_beta': 1.0, 'soft_f1_eps': 1e-06, 'label_smoothing': 0.1, 'nine_class_head_enabled': True, 'nine_class_loss_weight': 0.2}, 'acls': {'label_smoothing_alpha': 0.1, 'mbls_margin': 10.0, 'mbls_alpha': 0.1, 'mbls_schedule': None, 'acls_pos_lambda': 1.0, 'acls_neg_lambda': 0.1, 'acls_alpha': 0.1, 'acls_margin': 10.0}, 'length_grouping': {'enabled': False, 'use_dynamic_padding': False, 'mega_batch_multiplier': 8, 'percentile_max_length': 0.95, 'min_sequence_length': 50, 'max_sequence_length': 500, 'put_longest_first': True, 'fallback_to_fixed_length': True}, 'schedule_free': {'enabled': False, 'optimizer_type': 'RAdamScheduleFree', 'learning_rate_multiplier': 5.0, 'warmup_steps': 1000, 'batch_norm_calibration_steps': 50}, 'ema': {'enabled': True, 'beta': 0.9999, 'update_after_step': 1000, 'update_every': 10, 'update_model_with_ema_every': 1000, 'use_ema_for_validation': True}, 'val': {'name': 'stratified_group_kfold', 'params': {'n_splits': 5, 'random_state': 42, 'target': 'gesture', 'group': 'subject', 'id': 'sequence_id', 'force_recreate': False}}, 'preprocessing': {'target_sequence_length': 200}, 'augmentation': {'gaussian_noise_prob': 0.3, 'gaussian_noise_std': 0.01, 'time_scaling_prob': 0.3, 'time_scaling_range': [0.9, 1.1], 'partial_masking_prob': 0.2, 'partial_masking_length_range': [5, 20], 'partial_masking_ratio': 0.1, 'enable_handedness_flip': False, 'handedness_flip_prob': 0.5}, 'logging': {'wandb_enabled': True, 'wandb_project': 'CMI-Detect-Behavior-with-Sensor-Data', 'wandb_name': 'exp023', 'wandb_tags': ['exp023', 'bert', 'attention', 'transformer', 'squeezeformer']}, 'lightning': {'trainer': {'accelerator': 'auto', 'devices': 'auto', 'precision': '16-mixed', 'deterministic': False, 'benchmark': True, 'enable_checkpointing': True, 'log_every_n_steps': 10, 'check_val_every_n_epoch': 1, 'val_check_interval': 1.0}, 'callbacks': {'model_checkpoint': {'monitor': 'val_cmi_score', 'mode': 'max', 'save_top_k': 1, 'save_last': True, 'filename': 'epoch-{epoch:02d}-val_cmi_score-{val_cmi_score:.4f}', 'auto_insert_metric_name': False}, 'early_stopping': {'monitor': 'val_cmi_score', 'mode': 'max', 'patience': 15, 'min_delta': 0.001, 'verbose': True}, 'lr_monitor': {'logging_interval': 'epoch'}, 'rich_progress_bar': {'enable': False}}}, 'root': '../../../outputs/exp023', 'target_gestures': ['Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin', 'Neck - scratch', 'Cheek - pinch skin'], 'non_target_gestures': ['Drink from bottle/cup', 'Glasses on/off', 'Pull air toward your face', 'Pinch knee/leg skin', 'Scratch knee/leg skin', 'Write name on leg', 'Text on phone', 'Feel around in tray and pull out an object', 'Write name in air', 'Wave hello'], 'imu_features': ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']}
08/16/2025 08:13:34 PM INFO __main__: Starting training for fold 0
08/16/2025 08:15:14 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 08:27:27 PM INFO __main__: Loading best model from: ../../../outputs/exp023/fold_0/version_2/checkpoints/epoch-17-val_cmi_score-0.7539.ckpt
08/16/2025 08:27:31 PM INFO __main__: Fold 0 results: {'fold': 0, 'val_loss': 1.0029516220092773, 'val_cmi_score': 0.7539083361625671, 'val_multiclass_loss': 1.411414384841919, 'val_binary_loss': 0.1104569286108017, 'best_model_path': '../../../outputs/exp023/fold_0/version_2/checkpoints/epoch-17-val_cmi_score-0.7539.ckpt'}
08/16/2025 08:27:31 PM INFO __main__: Starting training for fold 1
08/16/2025 08:29:18 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 08:43:58 PM INFO __main__: Loading best model from: ../../../outputs/exp023/fold_1/version_0/checkpoints/epoch-25-val_cmi_score-0.7325.ckpt
08/16/2025 08:44:01 PM INFO __main__: Fold 1 results: {'fold': 1, 'val_loss': 1.421829342842102, 'val_cmi_score': 0.7325295805931091, 'val_multiclass_loss': 1.976630687713623, 'val_binary_loss': 0.2044571340084076, 'best_model_path': '../../../outputs/exp023/fold_1/version_0/checkpoints/epoch-25-val_cmi_score-0.7325.ckpt'}
08/16/2025 08:44:01 PM INFO __main__: Starting training for fold 2
08/16/2025 08:45:46 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 08:56:25 PM INFO __main__: Loading best model from: ../../../outputs/exp023/fold_2/version_0/checkpoints/epoch-12-val_cmi_score-0.7532.ckpt
08/16/2025 08:56:29 PM INFO __main__: Fold 2 results: {'fold': 2, 'val_loss': 0.8912345767021179, 'val_cmi_score': 0.7532081007957458, 'val_multiclass_loss': 1.248681902885437, 'val_binary_loss': 0.11693767458200455, 'best_model_path': '../../../outputs/exp023/fold_2/version_0/checkpoints/epoch-12-val_cmi_score-0.7532.ckpt'}
08/16/2025 08:56:29 PM INFO __main__: Starting training for fold 3
08/16/2025 08:58:12 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 09:12:58 PM INFO __main__: Loading best model from: ../../../outputs/exp023/fold_3/version_0/checkpoints/epoch-25-val_cmi_score-0.7526.ckpt
08/16/2025 09:13:02 PM INFO __main__: Fold 3 results: {'fold': 3, 'val_loss': 1.2268595695495605, 'val_cmi_score': 0.7525596022605896, 'val_multiclass_loss': 1.6955028772354126, 'val_binary_loss': 0.15056484937667847, 'best_model_path': '../../../outputs/exp023/fold_3/version_0/checkpoints/epoch-25-val_cmi_score-0.7526.ckpt'}
08/16/2025 09:13:02 PM INFO __main__: Starting training for fold 4
08/16/2025 09:14:43 PM INFO __main__: Using input_dim=16 (HN features: False)
08/16/2025 09:28:23 PM INFO __main__: Loading best model from: ../../../outputs/exp023/fold_4/version_0/checkpoints/epoch-22-val_cmi_score-0.7485.ckpt
08/16/2025 09:28:27 PM INFO __main__: Fold 4 results: {'fold': 4, 'val_loss': 1.1253775358200073, 'val_cmi_score': 0.7485353946685791, 'val_multiclass_loss': 1.5490155220031738, 'val_binary_loss': 0.15971623361110687, 'best_model_path': '../../../outputs/exp023/fold_4/version_0/checkpoints/epoch-22-val_cmi_score-0.7485.ckpt'}
08/16/2025 09:28:27 PM INFO __main__: Cross-validation completed
08/16/2025 09:28:27 PM INFO __main__: Mean CV Loss: 1.1337 ± 0.1831
08/16/2025 09:28:27 PM INFO __main__: Mean CV CMI Score: 0.7481 ± 0.0080
08/16/2025 09:28:27 PM INFO __main__: Results saved to: ../../../outputs/exp023/cv_results.csv
08/16/2025 09:28:27 PM INFO __main__: CV results logged to WandB
