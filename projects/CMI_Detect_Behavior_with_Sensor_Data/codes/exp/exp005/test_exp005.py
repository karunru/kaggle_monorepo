"""exp005ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆLength Grouping + Schedule Freeçµ±åˆï¼‰."""

import sys
from pathlib import Path

# Add current directory to path for imports
sys.path.append(str(Path(__file__).parent))


def test_imports():
    """åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ."""
    try:
        import config
        import dataset
        import model

        print("âœ“ dataset.py, model.py, and config.py imports successful")
        return True
    except ImportError as e:
        print(f"âœ— Import failed: {e}")
        return False


def test_config_class():
    """Configã‚¯ãƒ©ã‚¹ã®å­˜åœ¨ç¢ºèª."""
    try:
        from config import Config

        print("âœ“ Config class is available")
        return True
    except ImportError:
        print("âœ— Config class not found")
        return False


def test_pydantic_config():
    """pydantic-settings Config ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ."""
    try:
        from config import Config

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        config = Config()
        print("âœ“ Config class instantiation successful")

        # å±æ€§ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
        assert config.model.input_dim == 7
        assert config.training.batch_size == 128  # exp005ã§ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’128ã«å¤‰æ›´
        assert config.model.d_model == 256
        assert len(config.target_gestures) == 8
        assert len(config.imu_features) == 7
        print("âœ“ Config attribute access successful")

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
        assert 0 <= config.model.dropout <= 1
        assert config.training.learning_rate > 0
        assert config.training.batch_size > 0
        print("âœ“ Config validation successful")

        # dictå¤‰æ›ãƒ†ã‚¹ãƒˆ
        config_dict = config.model_dump()
        assert isinstance(config_dict, dict)
        assert "model" in config_dict
        assert "training" in config_dict
        print("âœ“ Config dict conversion successful")

        return True

    except Exception as e:
        print(f"âœ— pydantic Config test failed: {e}")
        return False


def test_length_grouped_sampler():
    """LengthGroupedSamplerã®ãƒ†ã‚¹ãƒˆ."""
    try:
        from dataset import LengthGroupedSampler

        print("âœ“ LengthGroupedSampler import successful")
        return True
    except ImportError:
        print("âœ— LengthGroupedSampler not found")
        return False


def test_dynamic_collate_fn():
    """å‹•çš„Collateé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ."""
    try:
        from dataset import dynamic_collate_fn

        print("âœ“ dynamic_collate_fn import successful")
        return True
    except ImportError:
        print("âœ— dynamic_collate_fn not found")
        return False


def test_length_grouping_config():
    """LengthGroupingConfigã®ãƒ†ã‚¹ãƒˆ."""
    try:
        from config import Config

        config = Config()

        # Length Groupingè¨­å®šã®ãƒ†ã‚¹ãƒˆ
        assert hasattr(config, "length_grouping")
        assert hasattr(config.length_grouping, "enabled")
        assert hasattr(config.length_grouping, "use_dynamic_padding")
        assert hasattr(config.length_grouping, "mega_batch_multiplier")
        assert hasattr(config.length_grouping, "percentile_max_length")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ãƒ†ã‚¹ãƒˆ
        assert config.length_grouping.mega_batch_multiplier >= 1
        assert 0 < config.length_grouping.percentile_max_length <= 1

        print("âœ“ LengthGroupingConfig test successful")
        return True
    except Exception as e:
        print(f"âœ— LengthGroupingConfig test failed: {e}")
        return False


def test_schedule_free_config():
    """ScheduleFreeConfigã®ãƒ†ã‚¹ãƒˆ."""
    try:
        from config import Config

        config = Config()

        # Schedule Freeè¨­å®šã®ãƒ†ã‚¹ãƒˆ
        assert hasattr(config, "schedule_free")
        assert hasattr(config.schedule_free, "enabled")
        assert hasattr(config.schedule_free, "optimizer_type")
        assert hasattr(config.schedule_free, "learning_rate_multiplier")
        assert hasattr(config.schedule_free, "warmup_steps")
        assert hasattr(config.schedule_free, "batch_norm_calibration_steps")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ãƒ†ã‚¹ãƒˆ
        assert config.schedule_free.learning_rate_multiplier > 0
        assert config.schedule_free.warmup_steps >= 0
        assert config.schedule_free.batch_norm_calibration_steps >= 1
        assert config.schedule_free.optimizer_type in ["RAdamScheduleFree", "AdamWScheduleFree", "SGDScheduleFree"]

        print("âœ“ ScheduleFreeConfig test successful")
        return True
    except Exception as e:
        print(f"âœ— ScheduleFreeConfig test failed: {e}")
        return False


def test_basic_functionality():
    """åŸºæœ¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ."""
    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ãƒ†ã‚¹ãƒˆ
        from model import CMISqueezeformer

        model = CMISqueezeformer(
            input_dim=7,
            d_model=64,  # å°ã•ã„ã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
            n_layers=2,
            n_heads=4,
            d_ff=256,
            num_classes=18,
        )
        print("âœ“ Model instantiation successful")

        # å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆPyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        try:
            import torch

            test_input = torch.randn(1, 7, 100)  # [batch, features, seq_len]
            attention_mask = torch.ones(1, 100, dtype=torch.bool)  # exp005ã§ã¯ attention mask è¿½åŠ 

            multiclass_logits, binary_logits = model(test_input, attention_mask)

            assert multiclass_logits.shape == (1, 18)
            assert binary_logits.shape == (1, 1)
            print("âœ“ Model forward pass with attention mask successful")
            return True
        except ImportError:
            print("! PyTorch not available, skipping forward pass test")
            return True

    except Exception as e:
        print(f"âœ— Basic functionality test failed: {e}")
        return False


def test_schedule_free_imports():
    """Schedule Free optimizer importã®ãƒ†ã‚¹ãƒˆ."""
    try:
        # Schedule Free optimizerãŒåˆ©ç”¨å¯èƒ½ã‹ãƒ†ã‚¹ãƒˆ
        from model import SCHEDULEFREE_AVAILABLE

        print(f"âœ“ Schedule Free availability: {SCHEDULEFREE_AVAILABLE}")

        if SCHEDULEFREE_AVAILABLE:
            print("âœ“ Schedule Free optimizers are available")
        else:
            print("! Schedule Free optimizers not available (optional dependency)")

        return True
    except Exception as e:
        print(f"âœ— Schedule Free import test failed: {e}")
        return False


def test_integrated_functionality():
    """çµ±åˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆï¼ˆLength Grouping + Schedule Freeï¼‰."""
    try:
        from config import Config
        from model import CMISqueezeformer

        # çµ±åˆè¨­å®šã®ä½œæˆ
        config = Config()
        config.length_grouping.enabled = True
        config.length_grouping.use_dynamic_padding = True
        config.schedule_free.enabled = False  # ãƒ†ã‚¹ãƒˆç”¨ã«ç„¡åŠ¹åŒ–ï¼ˆä¾å­˜é–¢ä¿‚ãªã—ã§ãƒ†ã‚¹ãƒˆï¼‰

        # ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆçµ±åˆè¨­å®šä»˜ãï¼‰
        model = CMISqueezeformer(
            input_dim=config.model.input_dim,
            d_model=64,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            n_layers=2,
            n_heads=4,
            d_ff=256,
            num_classes=config.model.num_classes,
            schedule_free_config=config.schedule_free.model_dump(),
        )

        print("âœ“ Integrated model creation successful")

        # è¨­å®šã®æ¤œè¨¼
        assert hasattr(config, "length_grouping")
        assert hasattr(config, "schedule_free")
        print("âœ“ Integrated configuration access successful")

        return True
    except Exception as e:
        print(f"âœ— Integrated functionality test failed: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°."""
    print("Running exp005 tests...")
    print("=" * 40)

    tests = [
        test_imports,
        test_config_class,
        test_pydantic_config,
        test_length_grouped_sampler,
        test_dynamic_collate_fn,
        test_length_grouping_config,
        test_schedule_free_config,
        test_schedule_free_imports,
        test_basic_functionality,
        test_integrated_functionality,
    ]

    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"âœ— Test {test.__name__} failed with exception: {e}")
            results.append(False)
        print()

    # ã‚µãƒãƒªãƒ¼
    passed = sum(results)
    total = len(results)
    print("=" * 40)
    print(f"Tests passed: {passed}/{total}")

    if passed == total:
        print("ğŸ‰ All tests passed!")
        return True
    else:
        print("âŒ Some tests failed")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
