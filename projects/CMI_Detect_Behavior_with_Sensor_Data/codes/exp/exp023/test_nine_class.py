"""exp023ã®9ã‚¯ãƒ©ã‚¹ãƒ˜ãƒƒãƒ‰å®Ÿè£…ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ."""

import torch
from config import Config
from dataset import IMUDataset
from model import CMISqueezeformer


def test_config():
    """è¨­å®šã®ç¢ºèª."""
    config = Config()
    print("=== Config Test ===")
    print(f"hn_enabled: {config.demographics.hn_enabled}")
    print(f"loss.type: {config.loss.type}")
    print(f"nine_class_head_enabled: {config.loss.nine_class_head_enabled}")
    print(f"nine_class_loss_weight: {config.loss.nine_class_loss_weight}")
    assert config.demographics.hn_enabled is False, "hn_enabled should be False"
    assert config.loss.type == "acls", "loss.type should be 'acls'"
    assert config.loss.nine_class_head_enabled is True, "nine_class_head_enabled should be True"
    print("âœ“ Config test passed")


def test_dataset():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®9ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ç”Ÿæˆã®ç¢ºèª."""
    config = Config()
    print("\n=== Dataset Test ===")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    try:
        dataset = IMUDataset(
            train_csv="dummy",  # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§ã¯ãªã„
            config=config,
            is_train=True
        )
        print("âœ“ Dataset initialization test would pass with real data")
    except Exception as e:
        print(f"Dataset test skipped (expected with dummy data): {e}")

    # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã®ç¢ºèª
    target_gestures = [
        "Above ear - pull hair",
        "Forehead - pull hairline",
        "Forehead - scratch",
        "Eyebrow - pull hair",
        "Eyelash - pull hair",
        "Neck - pinch skin",
        "Neck - scratch",
        "Cheek - pinch skin",
    ]

    non_target_gestures = [
        "Drink from bottle/cup",
        "Glasses on/off",
        "Pull air toward your face",
        "Pinch knee/leg skin",
        "Scratch knee/leg skin",
        "Write name on leg",
        "Text on phone",
        "Feel around in tray and pull out an object",
        "Write name in air",
        "Wave hello",
    ]

    # 9ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°ã®æ‰‹å‹•ç¢ºèª
    gesture_to_nine_class_id = {}
    for idx, gesture in enumerate(target_gestures):
        gesture_to_nine_class_id[gesture] = idx  # 0-7: target gestures
    for gesture in non_target_gestures:
        gesture_to_nine_class_id[gesture] = 8  # 8: all non-target gestures

    print(f"Target gestures mapped to 0-7: {len(target_gestures)}")
    print(f"Non-target gestures mapped to 8: {len(non_target_gestures)}")
    print("âœ“ Dataset mapping test passed")


def test_model():
    """ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèª."""
    config = Config()
    print("\n=== Model Test ===")

    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model = CMISqueezeformer(
        input_dim=config.model.input_dim,
        d_model=config.model.d_model,
        n_layers=config.model.n_layers,
        n_heads=config.model.n_heads,
        d_ff=config.model.d_ff,
        num_classes=config.model.num_classes,
        kernel_size=config.model.kernel_size,
        dropout=config.model.dropout,
        learning_rate=config.training.learning_rate,
        weight_decay=config.training.weight_decay,
        loss_config=config.loss.model_dump(),
        acls_config=config.acls.model_dump(),
        target_gestures=config.target_gestures,
        non_target_gestures=config.non_target_gestures,
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    batch_size = 2
    seq_len = 200
    imu_data = torch.randn(batch_size, config.model.input_dim, seq_len)

    # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
    multiclass_logits, binary_logits, nine_class_logits = model(imu_data)

    print(f"Input shape: {imu_data.shape}")
    print(f"Multiclass output shape: {multiclass_logits.shape}")
    print(f"Binary output shape: {binary_logits.shape}")
    print(f"Nine-class output shape: {nine_class_logits.shape}")

    # å½¢çŠ¶ã®ç¢ºèª
    assert multiclass_logits.shape == (batch_size, 18), f"Multiclass shape mismatch: {multiclass_logits.shape}"
    assert binary_logits.shape == (batch_size, 1), f"Binary shape mismatch: {binary_logits.shape}"
    assert nine_class_logits.shape == (batch_size, 9), f"Nine-class shape mismatch: {nine_class_logits.shape}"

    print("âœ“ Model forward test passed")

    # æå¤±è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ
    multiclass_labels = torch.randint(0, 18, (batch_size,))
    binary_labels = torch.randint(0, 2, (batch_size,)).float()
    nine_class_labels = torch.randint(0, 9, (batch_size,))

    # æå¤±è¨ˆç®—
    multiclass_loss = model.multiclass_criterion(multiclass_logits, multiclass_labels)
    binary_loss = model.binary_criterion(binary_logits.squeeze(-1), binary_labels)
    nine_class_loss = model.nine_class_criterion(nine_class_logits, nine_class_labels)

    total_loss = (model.loss_alpha * multiclass_loss +
                 (1 - model.loss_alpha) * binary_loss +
                 model.nine_class_loss_weight * nine_class_loss)

    print(f"Multiclass loss: {multiclass_loss.item():.4f}")
    print(f"Binary loss: {binary_loss.item():.4f}")
    print(f"Nine-class loss: {nine_class_loss.item():.4f}")
    print(f"Total loss: {total_loss.item():.4f}")

    assert not torch.isnan(total_loss), "Total loss should not be NaN"
    print("âœ“ Model loss computation test passed")

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç¢ºèª
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")

    print("âœ“ Model test completed successfully")


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°."""
    print("Starting exp023 nine-class head implementation test...")

    try:
        test_config()
        test_dataset()
        test_model()
        print("\nğŸ‰ All tests passed successfully!")

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        raise


if __name__ == "__main__":
    main()
