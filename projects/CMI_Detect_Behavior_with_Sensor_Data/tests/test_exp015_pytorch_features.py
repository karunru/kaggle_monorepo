"""exp015ç”¨ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ - PyTorchç‰¹å¾´é‡æŠ½å‡ºçµ±åˆç‰ˆ."""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parents[1]
sys.path.append(str(project_root))
sys.path.append(str(project_root / "codes" / "exp" / "exp015"))

import numpy as np
import polars as pl
import torch
from codes.exp.exp015.config import Config
from codes.exp.exp015.dataset import IMUDataset
from codes.exp.exp015.model import CMISqueezeformer, IMUFeatureExtractor


class TestIMUFeatureExtractor:
    """IMUç‰¹å¾´é‡æŠ½å‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ."""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—."""
        self.batch_size = 4
        self.seq_len = 100
        self.input_dim = 7  # acc_x/y/z, rot_w/x/y/z
        self.feature_extractor = IMUFeatureExtractor(sampling_rate=100.0, cutoff_freq=10.0, filter_order=15)

    def test_feature_extractor_initialization(self):
        """ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ."""
        extractor = IMUFeatureExtractor()
        assert extractor.sampling_rate == 100.0
        assert extractor.cutoff_freq == 10.0
        assert extractor.filter_size == 15

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®é‡ã¿ãŒæ­£ã—ãåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        assert extractor.lpf_acc.weight.requires_grad is False
        assert extractor.lpf_ang_vel.weight.requires_grad is False

    def test_feature_extractor_output_shape(self):
        """ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®å‡ºåŠ›å½¢çŠ¶ãƒ†ã‚¹ãƒˆ."""
        # ãƒ©ãƒ³ãƒ€ãƒ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        imu_data = torch.randn(self.batch_size, self.input_dim, self.seq_len)

        # ç‰¹å¾´é‡æŠ½å‡º
        features = self.feature_extractor(imu_data)

        # å‡ºåŠ›å½¢çŠ¶ã®ç¢ºèª (39æ¬¡å…ƒã®æ‹¡å¼µç‰¹å¾´é‡)
        expected_output_dim = 39
        assert features.shape == (self.batch_size, expected_output_dim, self.seq_len)

        # NaNå€¤ãŒå«ã¾ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        assert not torch.isnan(features).any()

    def test_remove_gravity_functionality(self):
        """é‡åŠ›é™¤å»æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ."""
        # ãƒ†ã‚¹ãƒˆç”¨ã®åŠ é€Ÿåº¦ã¨å››å…ƒæ•°ãƒ‡ãƒ¼ã‚¿
        acc = torch.tensor([[[0.0, 0.0, 9.81]]], dtype=torch.float32).transpose(-1, -2)  # [1, 3, 1]
        quat = torch.tensor([[[1.0, 0.0, 0.0, 0.0]]], dtype=torch.float32).transpose(-1, -2)  # [1, 4, 1]

        linear_acc = self.feature_extractor.remove_gravity(acc, quat)

        # å½¢çŠ¶ç¢ºèª
        assert linear_acc.shape == (1, 3, 1)

        # é‡åŠ›ãŒé™¤å»ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆå®Œå…¨ã«ã‚¼ãƒ­ã«ã¯ãªã‚‰ãªã„ãŒè¿‘ã„å€¤ã«ãªã‚‹ï¼‰
        assert linear_acc.abs().max() < 1.0  # è¨±å®¹èª¤å·®

    def test_quaternion_to_angular_velocity(self):
        """å››å…ƒæ•°ã‹ã‚‰è§’é€Ÿåº¦ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ."""
        # å˜ä½å››å…ƒæ•°ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        quat = torch.tensor([[[1.0, 0.0, 0.0, 0.0], [0.707, 0.707, 0.0, 0.0]]], dtype=torch.float32).transpose(
            -1, -2
        )  # [1, 4, 2]

        angular_vel = self.feature_extractor.quaternion_to_angular_velocity(quat)

        # å½¢çŠ¶ç¢ºèª
        assert angular_vel.shape == (1, 3, 2)

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(angular_vel).all()

    def test_calculate_angular_distance(self):
        """è§’è·é›¢è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ."""
        # å˜ä½å››å…ƒæ•°ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        quat = torch.tensor([[[1.0, 0.0, 0.0, 0.0], [0.707, 0.707, 0.0, 0.0]]], dtype=torch.float32).transpose(
            -1, -2
        )  # [1, 4, 2]

        angular_distance = self.feature_extractor.calculate_angular_distance(quat)

        # å½¢çŠ¶ç¢ºèª
        assert angular_distance.shape == (1, 1, 2)

        # 0ä»¥ä¸Šã®å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert (angular_distance >= 0).all()

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(angular_distance).all()

    def test_gradient_flow(self):
        """å‹¾é…ã®æµã‚Œã‚‹ãƒ†ã‚¹ãƒˆ."""
        # å‹¾é…è¨ˆç®—ãŒå¿…è¦ãªå…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«
        imu_data = torch.randn(2, 7, 50, requires_grad=True)

        # ç‰¹å¾´é‡æŠ½å‡º
        features = self.feature_extractor(imu_data)

        # æå¤±è¨ˆç®—ï¼ˆå˜ç´”ãªåˆè¨ˆï¼‰
        loss = features.sum()

        # é€†ä¼æ’­
        loss.backward()

        # å‹¾é…ãŒæµã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert imu_data.grad is not None
        assert not torch.isnan(imu_data.grad).any()


class TestCMISqueezeformerIntegration:
    """CMISqueezeformerã¨IMUç‰¹å¾´é‡æŠ½å‡ºå™¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ."""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—."""
        self.config = Config()
        self.batch_size = 4
        self.seq_len = 100
        self.input_dim = 7
        self.num_classes = 18

        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        self.model = CMISqueezeformer(
            input_dim=self.input_dim,
            feature_extractor_config=self.config.feature_extractor.model_dump(),
            d_model=256,
            n_layers=2,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            n_heads=4,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            d_ff=512,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            num_classes=self.num_classes,
            dropout=0.1,
        )

    def test_model_initialization(self):
        """ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã®ãƒ†ã‚¹ãƒˆ."""
        assert self.model.input_dim == 7
        assert self.model.extracted_feature_dim == 39
        assert self.model.num_classes == self.num_classes

        # ç‰¹å¾´é‡æŠ½å‡ºå™¨ãŒæ­£ã—ãåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        assert isinstance(self.model.imu_feature_extractor, IMUFeatureExtractor)
        assert self.model.input_projection.in_features == 39  # æ‹¡å¼µç‰¹å¾´é‡ã®æ¬¡å…ƒ

    def test_forward_pass_basic(self):
        """åŸºæœ¬çš„ãªé †ä¼æ’­ãƒ†ã‚¹ãƒˆ."""
        # ãƒ©ãƒ³ãƒ€ãƒ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        imu_data = torch.randn(self.batch_size, self.input_dim, self.seq_len)

        # é †ä¼æ’­
        multiclass_logits, binary_logits = self.model(imu_data)

        # å‡ºåŠ›å½¢çŠ¶ã®ç¢ºèª
        assert multiclass_logits.shape == (self.batch_size, self.num_classes)
        assert binary_logits.shape == (self.batch_size, 1)

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(multiclass_logits).all()
        assert torch.isfinite(binary_logits).all()

    def test_forward_pass_with_attention_mask(self):
        """Attention Maskã‚ã‚Šã®é †ä¼æ’­ãƒ†ã‚¹ãƒˆ."""
        # ãƒ©ãƒ³ãƒ€ãƒ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        imu_data = torch.randn(self.batch_size, self.input_dim, self.seq_len)

        # Attention Maskï¼ˆæœ€åˆã®åŠåˆ†ã‚’æœ‰åŠ¹ã«ï¼‰
        attention_mask = torch.zeros(self.batch_size, self.seq_len, dtype=torch.bool)
        attention_mask[:, : self.seq_len // 2] = True

        # é †ä¼æ’­
        multiclass_logits, binary_logits = self.model(imu_data, attention_mask=attention_mask)

        # å‡ºåŠ›å½¢çŠ¶ã®ç¢ºèª
        assert multiclass_logits.shape == (self.batch_size, self.num_classes)
        assert binary_logits.shape == (self.batch_size, 1)

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(multiclass_logits).all()
        assert torch.isfinite(binary_logits).all()

    def test_forward_pass_with_demographics(self):
        """Demographicsç‰¹å¾´é‡ã‚ã‚Šã®é †ä¼æ’­ãƒ†ã‚¹ãƒˆ."""
        # Demographicsçµ±åˆã‚’æœ‰åŠ¹ã«ã—ãŸãƒ¢ãƒ‡ãƒ«
        model_with_demo = CMISqueezeformer(
            input_dim=self.input_dim,
            feature_extractor_config=self.config.feature_extractor.model_dump(),
            demographics_config={"enabled": True, "embedding_dim": 16},
            d_model=256,
            n_layers=2,
            n_heads=4,
            d_ff=512,
            num_classes=self.num_classes,
        )

        # ãƒ©ãƒ³ãƒ€ãƒ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        imu_data = torch.randn(self.batch_size, self.input_dim, self.seq_len)

        # ãƒ€ãƒŸãƒ¼Demographicsç‰¹å¾´é‡
        demographics = {
            "adult_child": torch.randint(0, 2, (self.batch_size,)),
            "sex": torch.randint(0, 2, (self.batch_size,)),
            "handedness": torch.randint(0, 2, (self.batch_size,)),
            "age": torch.randint(18, 65, (self.batch_size,)).float(),
            "height_cm": torch.randint(150, 190, (self.batch_size,)).float(),
            "shoulder_to_wrist_cm": torch.randint(40, 70, (self.batch_size,)).float(),
            "elbow_to_wrist_cm": torch.randint(20, 40, (self.batch_size,)).float(),
        }

        # é †ä¼æ’­
        multiclass_logits, binary_logits = model_with_demo(imu_data, demographics=demographics)

        # å‡ºåŠ›å½¢çŠ¶ã®ç¢ºèª
        assert multiclass_logits.shape == (self.batch_size, self.num_classes)
        assert binary_logits.shape == (self.batch_size, 1)

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(multiclass_logits).all()
        assert torch.isfinite(binary_logits).all()

    def test_parameter_count(self):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç¢ºèª."""
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert total_params > 0
        assert trainable_params > 0

        # è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert trainable_params <= total_params

        print(f"Total parameters: {total_params:,}")
        print(f"Trainable parameters: {trainable_params:,}")

    def test_training_mode(self):
        """è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ."""
        self.model.train()

        # ãƒ©ãƒ³ãƒ€ãƒ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        imu_data = torch.randn(self.batch_size, self.input_dim, self.seq_len)

        # é †ä¼æ’­
        multiclass_logits, binary_logits = self.model(imu_data)

        # æå¤±è¨ˆç®—
        target_multiclass = torch.randint(0, self.num_classes, (self.batch_size,))
        target_binary = torch.randint(0, 2, (self.batch_size,)).float()

        loss_multiclass = torch.nn.functional.cross_entropy(multiclass_logits, target_multiclass)
        loss_binary = torch.nn.functional.binary_cross_entropy_with_logits(binary_logits.squeeze(), target_binary)

        total_loss = loss_multiclass + loss_binary

        # é€†ä¼æ’­ã®ãƒ†ã‚¹ãƒˆ
        total_loss.backward()

        # å‹¾é…ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert param.grad is not None, f"Gradient not found for {name}"
                assert not torch.isnan(param.grad).any(), f"NaN gradient found for {name}"


class TestDatasetIntegration:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±åˆãƒ†ã‚¹ãƒˆ."""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—."""
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        self.df = self._create_dummy_data()
        self.config = Config()

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        self.dataset = IMUDataset(self.df, target_sequence_length=100, augment=False, use_dynamic_padding=False)

    def _create_dummy_data(self) -> pl.DataFrame:
        """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ."""
        sequences = []
        gestures = ["Above ear - pull hair", "Forehead - pull hairline", "Drink from bottle/cup", "Glasses on/off"]

        for seq_id in range(10):
            seq_len = np.random.randint(50, 150)

            data = {
                "sequence_id": [seq_id] * seq_len,
                "sequence_counter": list(range(seq_len)),
                "gesture": [gestures[seq_id % len(gestures)]] * seq_len,
                "acc_x": np.random.randn(seq_len),
                "acc_y": np.random.randn(seq_len),
                "acc_z": np.random.randn(seq_len),
                "rot_w": np.random.randn(seq_len),
                "rot_x": np.random.randn(seq_len),
                "rot_y": np.random.randn(seq_len),
                "rot_z": np.random.randn(seq_len),
            }

            sequences.append(pl.DataFrame(data))

        return pl.concat(sequences)

    def test_dataset_initialization(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ."""
        assert len(self.dataset) == 10  # 10ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
        assert len(self.dataset.imu_cols) == 7  # åŸºæœ¬IMUç‰¹å¾´é‡ã®ã¿
        assert self.dataset.num_classes == 4  # 4ã¤ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼

    def test_dataset_getitem(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ."""
        sample = self.dataset[0]

        # ã‚­ãƒ¼ã®ç¢ºèª
        expected_keys = {"imu", "multiclass_label", "binary_label", "sequence_id", "gesture", "missing_mask"}
        assert set(sample.keys()) == expected_keys

        # IMUãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ç¢ºèªï¼ˆ7æ¬¡å…ƒã®åŸºæœ¬ç‰¹å¾´é‡ï¼‰
        assert sample["imu"].shape[0] == 7  # åŸºæœ¬IMUç‰¹å¾´é‡
        assert sample["imu"].shape[1] == 100  # target_sequence_length

        # ãƒ©ãƒ™ãƒ«ã®ç¢ºèª
        assert isinstance(sample["multiclass_label"], torch.Tensor)
        assert isinstance(sample["binary_label"], torch.Tensor)
        assert isinstance(sample["missing_mask"], torch.Tensor)

        # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
        assert sample["imu"].dtype == torch.float32
        assert sample["multiclass_label"].dtype == torch.long
        assert sample["binary_label"].dtype == torch.float32
        assert sample["missing_mask"].dtype == torch.bool


class TestEndToEndPipeline:
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ."""

    def test_complete_pipeline(self):
        """å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ."""
        # è¨­å®š
        config = Config()

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df = self._create_dummy_data()

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        dataset = IMUDataset(df, target_sequence_length=50, augment=False)

        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = CMISqueezeformer(
            input_dim=7,
            feature_extractor_config=config.feature_extractor.model_dump(),
            d_model=128,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            n_layers=2,
            n_heads=4,
            d_ff=256,
            num_classes=len(dataset.gesture_to_id),
            dropout=0.1,
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        from torch.utils.data import DataLoader

        dataloader = DataLoader(dataset, batch_size=4, shuffle=False)

        # 1ãƒãƒƒãƒã®å‡¦ç†
        batch = next(iter(dataloader))

        # ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
        model.eval()
        with torch.no_grad():
            multiclass_logits, binary_logits = model(
                batch["imu"],
                attention_mask=~batch["missing_mask"],  # missing_maskã®é€†
            )

        # å‡ºåŠ›ã®ç¢ºèª
        assert multiclass_logits.shape[0] == batch["imu"].shape[0]  # ãƒãƒƒãƒã‚µã‚¤ã‚º
        assert multiclass_logits.shape[1] == len(dataset.gesture_to_id)  # ã‚¯ãƒ©ã‚¹æ•°
        assert binary_logits.shape == (batch["imu"].shape[0], 1)

        # æœ‰é™å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert torch.isfinite(multiclass_logits).all()
        assert torch.isfinite(binary_logits).all()

        print("âœ“ End-to-end pipeline test passed!")

    def _create_dummy_data(self) -> pl.DataFrame:
        """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ."""
        sequences = []
        gestures = ["Above ear - pull hair", "Forehead - pull hairline", "Drink from bottle/cup", "Glasses on/off"]

        for seq_id in range(8):
            seq_len = np.random.randint(30, 80)

            data = {
                "sequence_id": [seq_id] * seq_len,
                "sequence_counter": list(range(seq_len)),
                "gesture": [gestures[seq_id % len(gestures)]] * seq_len,
                "acc_x": np.random.randn(seq_len),
                "acc_y": np.random.randn(seq_len),
                "acc_z": np.random.randn(seq_len),
                "rot_w": np.random.randn(seq_len),
                "rot_x": np.random.randn(seq_len),
                "rot_y": np.random.randn(seq_len),
                "rot_z": np.random.randn(seq_len),
            }

            sequences.append(pl.DataFrame(data))

        return pl.concat(sequences)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    test_classes = [
        TestIMUFeatureExtractor,
        TestCMISqueezeformerIntegration,
        TestDatasetIntegration,
        TestEndToEndPipeline,
    ]

    for test_class in test_classes:
        print(f"\n=== Running {test_class.__name__} ===")

        instance = test_class()
        instance.setup_method()

        # ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œ
        for method_name in dir(instance):
            if method_name.startswith("test_"):
                print(f"Running {method_name}...")
                try:
                    getattr(instance, method_name)()
                    print(f"âœ“ {method_name} passed")
                except Exception as e:
                    print(f"âœ— {method_name} failed: {e}")
                    raise

    print("\nğŸ‰ All tests passed successfully!")
