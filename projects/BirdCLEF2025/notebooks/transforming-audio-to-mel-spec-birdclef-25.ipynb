{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# **BirdCLEF 2025 Data Preprocessing Notebook**\nThis notebook demonstrates how we can transform audio data into mel-spectrogram data. This transformation is essential for training 2D Convolutional Neural Networks (CNNs) on audio data, as it converts the one-dimensional audio signals into two-dimensional image-like representations.\nI run this public notebook in debug mode(only a few sample processing). You can find the fully preprocessed mel spectrogram training dataset here --> [BirdCLEF'25 | Mel Spectrograms](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms).\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEBUG_MODE = True\n",
    "\n",
    "    OUTPUT_DIR = \"/kaggle/working/\"\n",
    "    DATA_ROOT = \"/kaggle/input/birdclef-2025\"\n",
    "    FS = 32000\n",
    "\n",
    "    # Mel spectrogram parameters\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "\n",
    "    N_MAX = 50 if DEBUG_MODE else None\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Debug mode: {'ON' if config.DEBUG_MODE else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f\"{config.DATA_ROOT}/taxonomy.csv\")\n",
    "species_class_map = dict(zip(taxonomy_df[\"primary_label\"], taxonomy_df[\"class_name\"]))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f\"{config.DATA_ROOT}/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_list = sorted(train_df[\"primary_label\"].unique())\n",
    "label_id_list = list(range(len(label_list)))\n",
    "label2id = dict(zip(label_list, label_id_list))\n",
    "id2label = dict(zip(label_id_list, label_list))\n",
    "\n",
    "print(f\"Found {len(label_list)} unique species\")\n",
    "working_df = train_df[[\"primary_label\", \"rating\", \"filename\"]].copy()\n",
    "working_df[\"target\"] = working_df.primary_label.map(label2id)\n",
    "working_df[\"filepath\"] = config.DATA_ROOT + \"/train_audio/\" + working_df.filename\n",
    "working_df[\"samplename\"] = working_df.filename.map(lambda x: x.split(\"/\")[0] + \"-\" + x.split(\"/\")[-1].split(\".\")[0])\n",
    "working_df[\"class\"] = working_df.primary_label.map(lambda x: species_class_map.get(x, \"Unknown\"))\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f\"Total samples to process: {total_samples} out of {len(working_df)} available\")\n",
    "print(\"Samples by class:\")\n",
    "print(working_df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0,\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "\n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:01.589636Z",
     "iopub.status.busy": "2025-03-17T13:18:01.589211Z",
     "iopub.status.idle": "2025-03-17T13:18:25.526712Z",
     "shell.execute_reply": "2025-03-17T13:18:25.525599Z",
     "shell.execute_reply.started": "2025-03-17T13:18:01.589604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting audio processing...\")\n",
    "print(f\"{'DEBUG MODE - Processing only 50 samples' if config.DEBUG_MODE else 'FULL MODE - Processing all samples'}\")\n",
    "start_time = time.time()\n",
    "\n",
    "all_bird_data = {}\n",
    "errors = []\n",
    "\n",
    "for i, row in tqdm(working_df.iterrows(), total=total_samples):\n",
    "    if config.N_MAX is not None and i >= config.N_MAX:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        if len(audio_data) < target_samples:\n",
    "            n_copy = math.ceil(target_samples / len(audio_data))\n",
    "            if n_copy > 1:\n",
    "                audio_data = np.concatenate([audio_data] * n_copy)\n",
    "\n",
    "        start_idx = max(0, int(len(audio_data) / 2 - target_samples / 2))\n",
    "        end_idx = min(len(audio_data), start_idx + target_samples)\n",
    "        center_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "        if len(center_audio) < target_samples:\n",
    "            center_audio = np.pad(center_audio, (0, target_samples - len(center_audio)), mode=\"constant\")\n",
    "\n",
    "        mel_spec = audio2melspec(center_audio)\n",
    "\n",
    "        if mel_spec.shape != config.TARGET_SHAPE:\n",
    "            mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        all_bird_data[row.samplename] = mel_spec.astype(np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row.filepath}: {e}\")\n",
    "        errors.append((row.filepath, str(e)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Successfully processed {len(all_bird_data)} files out of {total_samples} total\")\n",
    "print(f\"Failed to process {len(errors)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:40.390482Z",
     "iopub.status.busy": "2025-03-17T13:18:40.389921Z",
     "iopub.status.idle": "2025-03-17T13:18:42.364716Z",
     "shell.execute_reply": "2025-03-17T13:18:42.363415Z",
     "shell.execute_reply.started": "2025-03-17T13:18:40.390449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples = []\n",
    "displayed_classes = set()\n",
    "\n",
    "max_samples = min(4, len(all_bird_data))\n",
    "\n",
    "for i, row in working_df.iterrows():\n",
    "    if i >= (config.N_MAX or len(working_df)):\n",
    "        break\n",
    "\n",
    "    if row[\"samplename\"] in all_bird_data:\n",
    "        if config.DEBUG_MODE:\n",
    "            if row[\"class\"] not in displayed_classes:\n",
    "                samples.append((row[\"samplename\"], row[\"class\"], row[\"primary_label\"]))\n",
    "                displayed_classes.add(row[\"class\"])\n",
    "        elif row[\"class\"] not in displayed_classes:\n",
    "            samples.append((row[\"samplename\"], row[\"class\"], row[\"primary_label\"]))\n",
    "            displayed_classes.add(row[\"class\"])\n",
    "\n",
    "        if len(samples) >= max_samples:\n",
    "            break\n",
    "\n",
    "if samples:\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    for i, (samplename, class_name, species) in enumerate(samples):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(all_bird_data[samplename], aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "        plt.title(f\"{class_name}: {species}\")\n",
    "        plt.colorbar(format=\"%+2.0f dB\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    debug_note = \"debug_\" if config.DEBUG_MODE else \"\"\n",
    "    plt.savefig(f\"{debug_note}melspec_examples.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}